<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic — Elastic Security Labs</title><meta name="description" content="In this article, we describe how we applied survival analysis to vulnerability management (VM) data from Qualys VMDR, using the Elastic Stack."/><meta property="og:title" content="Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic — Elastic Security Labs"/><meta property="og:description" content="In this article, we describe how we applied survival analysis to vulnerability management (VM) data from Qualys VMDR, using the Elastic Stack."/><meta property="og:image" content="https://www.elastic.co/security-labs/assets/images/time-to-patch-metrics/Security Labs Images 7.jpg?a0b1069f16229d89a2454ffec2de6605"/><meta property="og:image:alt" content="In this article, we describe how we applied survival analysis to vulnerability management (VM) data from Qualys VMDR, using the Elastic Stack."/><meta property="og:site_name"/><meta property="og:url" content="https://www.elastic.co/security-labs/time-to-patch-metrics"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic — Elastic Security Labs"/><meta name="twitter:description" content="In this article, we describe how we applied survival analysis to vulnerability management (VM) data from Qualys VMDR, using the Elastic Stack."/><meta name="twitter:image" content="https://www.elastic.co/security-labs/assets/images/time-to-patch-metrics/Security Labs Images 7.jpg?a0b1069f16229d89a2454ffec2de6605"/><meta name="twitter:image:alt" content="In this article, we describe how we applied survival analysis to vulnerability management (VM) data from Qualys VMDR, using the Elastic Stack."/><link rel="canonical" href="https://www.elastic.co/security-labs/time-to-patch-metrics"/><link rel="preload" href="/security-labs/logo.svg" as="image" fetchpriority="high"/><link rel="preload" as="image" imageSrcSet="/security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=640&amp;q=75 640w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=750&amp;q=75 750w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=828&amp;q=75 828w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=1080&amp;q=75 1080w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=1200&amp;q=75 1200w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=1920&amp;q=75 1920w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=2048&amp;q=75 2048w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=3840&amp;q=75 3840w" imageSizes="100vw" fetchpriority="high"/><meta name="next-head-count" content="19"/><script src="https://play.vidyard.com/embed/v4.js" type="text/javascript" async=""></script><link rel="icon" href="/security-labs/favicon.svg"/><link rel="mask-icon" href="/security-labs/favicon.svg" color="#1C1E23"/><link rel="apple-touch-icon" href="/security-labs/favicon.svg"/><meta name="theme-color" content="#1C1E23"/><link rel="preload" href="/security-labs/_next/static/media/8e9860b6e62d6359-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/security-labs/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/security-labs/_next/static/media/0ea4f4df910e6120-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/security-labs/_next/static/media/739c2d8941231bb4-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/security-labs/_next/static/media/ee71530a747ff30b-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/security-labs/_next/static/media/9fac010bc1f02be0-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/security-labs/_next/static/media/cbf5fbad4d73afac-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><script id="google-tag-manager" data-nscript="beforeInteractive">
          (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
          new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
          j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
          'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
          })(window,document,'script','dataLayer','GTM-KNJMG2M');
          </script><link rel="preload" href="/security-labs/_next/static/css/f666e49a9abb8918.css" as="style"/><link rel="stylesheet" href="/security-labs/_next/static/css/f666e49a9abb8918.css" data-n-g=""/><link rel="preload" href="/security-labs/_next/static/css/fc1dcb1d74b71e18.css" as="style"/><link rel="stylesheet" href="/security-labs/_next/static/css/fc1dcb1d74b71e18.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/security-labs/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/security-labs/_next/static/chunks/webpack-7987c6fda769d510.js" defer=""></script><script src="/security-labs/_next/static/chunks/framework-7a7e500878b44665.js" defer=""></script><script src="/security-labs/_next/static/chunks/main-ebd33a9f1cae5951.js" defer=""></script><script src="/security-labs/_next/static/chunks/pages/_app-7ddc1b0db09f2c64.js" defer=""></script><script src="/security-labs/_next/static/chunks/fec483df-43ee602fabdfe3a4.js" defer=""></script><script src="/security-labs/_next/static/chunks/352-a63885403f676dc6.js" defer=""></script><script src="/security-labs/_next/static/chunks/511-d08fe0fdd6f8a984.js" defer=""></script><script src="/security-labs/_next/static/chunks/848-7728ed7430cf686c.js" defer=""></script><script src="/security-labs/_next/static/chunks/402-94ac9b71a773ac81.js" defer=""></script><script src="/security-labs/_next/static/chunks/765-64491ec3f6a94272.js" defer=""></script><script src="/security-labs/_next/static/chunks/pages/%5Bslug%5D-740a124ff706010d.js" defer=""></script><script src="/security-labs/_next/static/t22lc240R6yUreqPiT9Cj/_buildManifest.js" defer=""></script><script src="/security-labs/_next/static/t22lc240R6yUreqPiT9Cj/_ssgManifest.js" defer=""></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KNJMG2M" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><main class="__variable_0351a5 __variable_a475ec __variable_ead7f7 flex flex-col min-h-screen"><div class="scroll-percentage-container"><div class="scroll-percentage-bar" style="width:0%"></div></div><div class="UtilityHeader_utilityHeader__T_Eto"><div class="UtilityHeader_utilityHeader__container__exgwf"><nav class="UtilityHeader_utilityLinks__ogtQ6"><h2 class="UtilityHeader_utilityHeading__0DExG">Explore Elastic: </h2><ul><li><a href="https://www.elastic.co">elastic.co</a></li><li><a href="https://www.elastic.co/search-labs">Search Labs</a></li><li><a href="https://www.elastic.co/observability-labs">Observability Labs</a></li></ul></nav></div></div><nav class="fixed w-full z-40 top-[29px]" data-headlessui-state=""><div class="bg-gradient-to-b from-zinc-900 from-20% h-[200%] to-transparent absolute inset-0 z-0 pointer-events-none"></div><div class="container relative z-10"><div class="flex h-16 items-center justify-between"><div class="flex items-center justify-start w-full"><div><a class="hover:opacity-50 transition" href="/security-labs"><img alt="elastic security labs logo" fetchpriority="high" width="200" height="30" decoding="async" data-nimg="1" style="color:transparent" src="/security-labs/logo.svg"/></a></div><div class="hidden lg:ml-6 lg:block"><div class="flex space-x-4"><a class="flex lg:inline-flex font-light my-1 py-1 px-2 font-display font-semibold lg:text-sm xl:text-base items-center transition hover:hover-link hover:text-white focus:accessible-link-focus" href="/security-labs/about"><span>About</span></a><div class="relative" data-headlessui-state=""><div><button class="flex lg:inline-flex font-light my-1 py-1 px-2 font-display font-semibold lg:text-sm xl:text-base items-center transition hover:hover-link hover:text-white focus:accessible-link-focus" id="headlessui-menu-button-:R2kq6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state="">Research<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="ml-1 -mr-1 h-4 w-4 text-zinc-400 relative top-[1px]"><path fill-rule="evenodd" d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z" clip-rule="evenodd"></path></svg></button></div></div><a class="flex lg:inline-flex font-light my-1 py-1 px-2 font-display font-semibold lg:text-sm xl:text-base items-center transition hover:hover-link hover:text-white focus:accessible-link-focus" href="/security-labs/category/product-updates"><span>Product Updates</span></a><a class="flex lg:inline-flex font-light my-1 py-1 px-2 font-display font-semibold lg:text-sm xl:text-base items-center transition hover:hover-link hover:text-white focus:accessible-link-focus" href="/security-labs/category/reports"><span>Reports</span></a><a class="flex lg:inline-flex font-light my-1 py-1 px-2 font-display font-semibold lg:text-sm xl:text-base items-center transition hover:hover-link hover:text-white focus:accessible-link-focus" href="/security-labs/category/enablement"><span>Enablement</span></a></div></div><div class="hidden lg:ml-auto lg:block"><div class="flex items-center space-x-4"><a class="rounded flex items-center p-4 text-white focus:outline-none focus:ring-0 focus:ring-offset-1 focus:ring-offset-zinc-600 group" href="https://search.elastic.co/?location%5B0%5D=Security%20Labs&amp;referrer=https://www.elastic.co/security-labs/time-to-patch-metrics"><div class="flex items-center relative font-display"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg></div></a><a class="flex lg:inline-flex font-light my-1 py-1 px-2 font-display font-semibold lg:text-sm xl:text-base items-center transition hover:hover-link hover:text-white focus:accessible-link-focus" href="https://www.elastic.co/security-labs/rss/feed.xml"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="h-4 w-4 mr-1"><path d="M3.75 3a.75.75 0 00-.75.75v.5c0 .414.336.75.75.75H4c6.075 0 11 4.925 11 11v.25c0 .414.336.75.75.75h.5a.75.75 0 00.75-.75V16C17 8.82 11.18 3 4 3h-.25z"></path><path d="M3 8.75A.75.75 0 013.75 8H4a8 8 0 018 8v.25a.75.75 0 01-.75.75h-.5a.75.75 0 01-.75-.75V16a6 6 0 00-6-6h-.25A.75.75 0 013 9.25v-.5zM7 15a2 2 0 11-4 0 2 2 0 014 0z"></path></svg><span class="hidden xl:block">Subscribe</span></a><a class="font-display inline-flex items-center justify-center rounded font-semibold disabled:!select-none disabled:!bg-gray-400 bg-blue-600 text-white hover:bg-blue-500 enabled:hover:text-white/80 transition-colors px-4 py-2 text-sm flex-1 lg:flex-auto" href="https://cloud.elastic.co/registration?cta=cloud-registration&amp;tech=trial&amp;plcmt=navigation&amp;pg=security-labs">Start free trial</a><a class="font-display inline-flex items-center justify-center rounded font-semibold text-white disabled:!select-none disabled:!bg-gray-400 button px-4 py-2 text-sm flex-1 lg:flex-auto" href="https://www.elastic.co/contact">Contact sales</a></div></div></div><div class="-mr-2 flex lg:hidden"><a class="rounded flex items-center p-4 text-white focus:outline-none focus:ring-0 focus:ring-offset-1 focus:ring-offset-zinc-600 group" href="https://search.elastic.co/?location%5B0%5D=Security%20Labs&amp;referrer=https://www.elastic.co/security-labs/time-to-patch-metrics"><div class="flex items-center relative font-display"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path></svg></div></a><button class="inline-flex items-center justify-center rounded-md p-2 text-gray-400 hover:bg-gray-700 hover:text-white focus:outline-none focus:ring-2 focus:ring-inset focus:ring-white" id="headlessui-disclosure-button-:R5a6:" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open navigation menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div></div></div></nav><main class="mb-20 flex-1 flex flex-col"><div class="h-48 md:h-64"><div class="after:absolute after:block after:bg-blue-400 after:blur-3xl after:content-[&#x27; &#x27;] after:h-96 after:opacity-5 after:right-0 after:rounded-full after:top-20 after:w-1/2 after:z-0 before:absolute before:block before:blur-3xl before:bg-orange-400 before:content-[&#x27; &#x27;] before:h-96 before:left-0 before:opacity-5 before:rounded-full before:w-1/2 before:z-0 w-full h-full relative"><div class="relative z-10 w-full h-[125%] -top-[25%] bg-no-repeat bg-cover bg-bottom flex items-center justify-center" style="background-image:url(/security-labs/grid.svg)"></div></div></div><article class="px-4"><div class="max-w-7xl mx-auto relative z-10 flex flex-col space-y-4"><div class="eyebrow break-words"><time class="block mb-2 md:mb-0 md:inline-block article-published-date" dateTime="2025-10-22T00:00:00.000Z">22 October 2025</time><span class="hidden md:inline-block md:mx-2">•</span><a class="hover:text-blue-400 text-xs md:text-sm whitespace-nowrap author-name" href="/security-labs/author/laura-voicu">Laura Voicu</a><span class="mx-2">•</span><a class="hover:text-blue-400 text-xs md:text-sm whitespace-nowrap author-name" href="/security-labs/author/clement-fouque">Clement Fouque</a></div><h1 class="font-bold leading-tighter text-3xl md:text-5xl"><span>Time-&nbsp;to-&nbsp;Patch Metrics: A Survival Analysis Approach Using Qualys and&nbsp;Elastic</span></h1><p class="text-zinc-200 text-base md:text-xl">In this article, we describe how we applied survival analysis to vulnerability management (VM) data from Qualys VMDR, using the Elastic Stack.</p><div class="flex items-center mt-4 text-zinc-200 text-sm space-x-4 border-t border-white/25 pt-4"><span class="flex items-center space-x-1"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-4 w-4 text-zinc-400"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6v6h4.5m4.5 0a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg><span>19 min read</span></span><span class="flex items-center space-x-1"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-4 w-4 text-zinc-400"><path stroke-linecap="round" stroke-linejoin="round" d="M9.568 3H5.25A2.25 2.25 0 003 5.25v4.318c0 .597.237 1.17.659 1.591l9.581 9.581c.699.699 1.78.872 2.607.33a18.095 18.095 0 005.223-5.223c.542-.827.369-1.908-.33-2.607L11.16 3.66A2.25 2.25 0 009.568 3z"></path><path stroke-linecap="round" stroke-linejoin="round" d="M6 6h.008v.008H6V6z"></path></svg><span><a class="hover:text-blue-400 whitespace-nowrap" href="/security-labs/category/enablement">Enablement</a></span></span></div></div><div class="max-w-7xl mx-auto"><div class="bg-zinc-900 border border-zinc-800 drop-shadow-lg p-5 sm:p-8 md:p-10 rounded-3xl mt-5 md:mt-10"><div class="relative w-full rounded-lg overflow-hidden aspect-video"><img alt="Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic" fetchpriority="high" decoding="async" data-nimg="fill" class="object-cover absolute h-full w-full" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="100vw" srcSet="/security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=640&amp;q=75 640w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=750&amp;q=75 750w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=828&amp;q=75 828w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=1080&amp;q=75 1080w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=1200&amp;q=75 1200w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=1920&amp;q=75 1920w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=2048&amp;q=75 2048w, /security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=3840&amp;q=75 3840w" src="/security-labs/_next/image?url=%2Fsecurity-labs%2Fassets%2Fimages%2Ftime-to-patch-metrics%2FSecurity%20Labs%20Images%207.jpg&amp;w=3840&amp;q=75"/><div class="absolute border border-white/50 inset-0 mix-blend-overlay rounded-lg z-10"></div></div></div></div><div class="lg:max-w-7xl mx-auto relative mt-12 lg:grid lg:grid-cols-4 lg:gap-8 items-start"><div class="flex justify-center lg:col-span-3"><div class="prose lg:prose-lg prose-invert w-full article-content"><div><h1 class="font-bold leading-tighter text-3xl md:text-5xl relative"><span id="time-to-patch-metrics-a-survival-analysis-approach-using-qualys-and-elastic" class="absolute -top-32"></span>Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic</h1>
<h2 class="font-bold text-2xl md:text-4xl relative"><span id="introduction" class="absolute -top-32"></span>Introduction</h2>
<p>Understanding how quickly vulnerabilities are remediated across different environments and teams is critical to maintaining a strong security posture. In this article, we describe how we applied <strong>survival analysis</strong> to vulnerability management (VM) data from <strong>Qualys VMDR</strong>, using the <strong>Elastic Stack</strong>. This allowed us to not only confirm general assumptions about team velocity (how quickly teams complete work) and remediation capacity (how much fixing they can take on) but also derive measurable insights. Since most of our security data is in the Elastic Stack, this process should be easily reproducible to other security data sources.</p>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="why-we-did-it" class="absolute -top-32"></span>Why We Did It</h3>
<p>Our primary motivation was to <strong>move from general assumptions to data-backed insights</strong> about:</p>
<ul>
<li>How quickly different teams and environments patch vulnerabilities</li>
<li>Whether patching performance meets internal service level objectives (SLOs)</li>
<li>Where bottlenecks or delays commonly occur</li>
<li>What other factors can affect patching performance</li>
</ul>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="why-survival-analysis-a-better-alternative-to-mean-time-to-remediate" class="absolute -top-32"></span>Why Survival Analysis? A Better Alternative to Mean Time to Remediate</h3>
<p>Mean Time to Remediate (MTTR) is commonly used to track how quickly vulnerabilities are patched, but both the mean and median suffer from significant limitations (we provide an example later in this article). The mean is highly sensitive to <em>outliers</em>[^1] and assumes the remediation times are evenly balanced around the average remediation time, which is rarely the case in practice. The median is less sensitive to extremes but discards information about the shape of the distribution and says nothing about the long tail of slow-to-patch vulnerabilities. Neither accounts for unresolved cases, i.e. vulnerabilities that remain open beyond the observation window, which are often excluded entirely. In practice, the vulnerabilities that remain open the longest are precisely the ones we should be most concerned about.</p>
<p><strong>Survival analysis</strong> addresses these limitations. Originating in medical and actuarial contexts, it models <strong>time-to-event data</strong> while explicitly incorporating <strong>censored observations</strong>, meaning in our context vulnerabilities that remain open. (For more details on its application to vulnerability management we strongly recommend <a href="https://www.themetricsmanifesto.com">“The Metrics Manifesto”</a>). Instead of collapsing remediation behavior into a single number, survival analysis estimates the probability that a vulnerability remains unpatched over time (e.g. 90% of vulnerabilities are remediated within 30 days). This allows for more meaningful assessments, such as the proportion of vulnerabilities patched within SLO (for example within 30, 90, or 180 days).</p>
<p>Survival analysis provides us with a <strong>survival function</strong> that estimates the probability a vulnerability remains unpatched over time.</p>
<p>:::
This method offers a better view of remediation performance, allowing us to assess not just how long vulnerabilities persist, but also how remediation behavior differs across systems, teams, or severity levels. It’s particularly well-suited to security data, which is often incomplete, skewed, and resistant to assumptions of normality.
:::</p>
<h2 class="font-bold text-2xl md:text-4xl relative"><span id="context" class="absolute -top-32"></span>Context</h2>
<p>Although we have applied survival analysis across different environments, teams and organizations, in this blog we focus on the results for the Elastic Cloud production environment.</p>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="vulnerability-age-calculation" class="absolute -top-32"></span>Vulnerability age calculation</h3>
<p>There are different methods to calculate vulnerability age.</p>
<p>For our internal metrics like <a href="https://www.elastic.co/blog/how-infosec-uses-elastic-stack-vulnerability-management">vulnerability adherence SLO</a>, we define vulnerability age as the difference between when a vulnerability was last found and when it was first detected (usually a few days after publication). This approach aims to penalize vulnerabilities that are reintroduced from an outdated base image. In the past, our base images were not updated frequently enough for our satisfaction. If a new instance is created, vulnerabilities can have a significant age (e.g., 100 days) from day one of discovery.</p>
<p>For this analysis, we find it more relevant to calculate the age based on the number of days between the last found date and the first found date. In this case, age represents the number of days the system was effectively exposed.</p>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="patch-everything-strategy" class="absolute -top-32"></span>“Patch everything” strategy</h3>
<p>In our Cloud environment, we maintain a policy to patch everything. This is because we almost exclusively use the same base image across all instances. Since Elastic Cloud operates fully on containers, there are no specific application packages (e.g., Elasticsearch) installed directly on our systems. Our fleet remains homogeneous as a result.</p>
<h2 class="font-bold text-2xl md:text-4xl relative"><span id="data-pipeline" class="absolute -top-32"></span>Data Pipeline</h2>
<p>Ingesting and mapping data into the Elastic Stack can be cumbersome. Luckily, we have <a href="https://www.elastic.co/integrations/data-integrations?solution=all-solutions&amp;category=security">many security integrations</a> that handle those natively, <a href="https://www.elastic.co/docs/reference/integrations/qualys_vmdr">Qualys VMDR</a> being one of them.</p>
<p>This integration has 3 main interests over custom ingestion methods (e.g. scripts, beats, …):</p>
<ul>
<li>It natively enriches vulnerability data from the Qualys Knowledge Base which add CVE IDs, threat intel information, … <strong>without needing to configure enrich pipelines</strong>.</li>
<li>Qualys data is already mapped to the Elastic Common Schema which is a standardized way of representing data, whether it’s coming from one source or another: for example, CVEs are always stored in field <a href="http://vulnerability.id"><em>vulnerability.id</em></a>, independent of the source.</li>
<li>A transform with the latest vulnerability is already set up. This index can be queried to get the latest vulnerabilities status.</li>
</ul>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="qualys-agent-integration-configuration" class="absolute -top-32"></span>Qualys agent integration configuration</h3>
<p>For survival analysis, we need to ingest both active and patched vulnerabilities. To analyze a specific period, we need to set the number of days in field <code class="px-1.5 py-1 rounded not-prose bg-[var(--tw-prose-invert-pre-bg)] whitespace-break-spaces text-[85%] text-emerald-600">max_days_since_detection_updated</code>. In our environment, we ingest Qualys data daily, so there’s no need to ingest a long history of fixed data, as we’ve already done that.</p>
<p>The Qualys VMDR elastic agent integration has been configured with the following:</p>
<div class="table-container"><table style="width:100%;table-layout:fixed;word-wrap:break-word"><thead><tr><th style="text-align:left">Property</th><th style="text-align:left">Value</th><th style="text-align:left">Comment</th></tr></thead><tbody><tr><td style="text-align:left">(Settings section) Username</td><td style="text-align:left"></td><td style="text-align:left"></td></tr><tr><td style="text-align:left">(Settings section) Password</td><td style="text-align:left"></td><td style="text-align:left">Since there are no API keys available in Qualys, we can only authenticate with Basic Authentication.  Make sure SSO is disabled on this account</td></tr><tr><td style="text-align:left">URL</td><td style="text-align:left"><a href="https://qualysapi.qg2.apps.qualys.com">https://qualysapi.qg2.apps.qualys.com</a> (for US2)</td><td style="text-align:left"><a href="https://www.qualys.com/platform-identification/">https://www.qualys.com/platform-identification/</a></td></tr><tr><td style="text-align:left">Interval</td><td style="text-align:left">4h</td><td style="text-align:left">Adjust it based on the number of ingested events.</td></tr><tr><td style="text-align:left">Input parameters</td><td style="text-align:left">show_asset_id=1&amp; include_vuln_type=confirmed&amp;show_results=1&amp;max_days_since_detection_updated=3&amp;status=New,Active,Re-Opened,Fixed&amp;filter_superseded_qids=1&amp;use_tags=1&amp;tag_set_by=name&amp;tag_include_selector=all&amp;tag_exclude_selector=any&amp;tag_set_include=status:running&amp;tag_set_exclude=status:terminated,status:stopped,status:stale&amp;show_tags=1&amp;show_cloud_tags=1</td><td style="text-align:left">show_asset_id=1: retrieve asset id show_results=1: details about what is the current installed package and which version should be installed max_days_since_detection_updated=3: filter out any vulnerabilities that haven’t been updated over the last 3 days (e.g. patched older than 3 days) status=New,Active,Re-Opened,Fixed: all vulnerability status are ingested filter_superseded_qids=1: ignore superseded ‘vulnerabilities Tags: filter by tags show_tags=1: retrieve Qualys tags show_cloud_tags=1: retrieve Cloud tags</td></tr></tbody></table></div>
<p>Once data is fully ingested, it can be reviewed either in Kibana Discover (logs-* data view -&gt; <em>data_stream.dataset : &quot;qualys_vmdr.asset_host_detection&quot;</em> ), either in the Kibana Security App (Findings -&gt; Vulnerabilities).</p>
<p></p>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="loading-data-into-python-with-the-elasticsearch-client" class="absolute -top-32"></span>Loading data into Python with the elasticsearch client</h3>
<p>Since the survival analysis calculation will be done in Python, we need to extract data from elastic into a python dataframe. There are several ways to achieve this, and in this article we’ll focus on two of them.</p>
<h4 class="font-bold leading-tight text-lg md:text-2xl relative"><span id="with-esql" class="absolute -top-32"></span>With ES|QL</h4>
<p>The easiest and most convenient way is to leverage ES|QL with the arrow format. It’ll automatically populate the python dataframe (rows and columns). We recommend reading the blog post <a href="https://www.elastic.co/search-labs/blog/esql-pandas-native-dataframes-python">From ES|QL to native Pandas dataframes in Python</a> to get more details.</p>
<pre><code>from elasticsearch import Elasticsearch
import pandas as pd

client = Elasticsearch(
    &quot;https://[host].elastic-cloud.com&quot;,
    api_key=&quot;...&quot;,
)

response = client.esql.query(
    query=&quot;&quot;&quot;
   FROM logs-qualys_vmdr.asset_host_detection-default
    | WHERE elastic.owner.team == &quot;platform-security&quot; AND elastic.environment == &quot;production&quot;
    | WHERE qualys_vmdr.asset_host_detection.vulnerability.is_ignored == FALSE
    | EVAL vulnerability_age = DATE_DIFF(&quot;day&quot;, qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime, qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime)
    | STATS 
        mean=AVG(vulnerability_age), 
        median=MEDIAN(vulnerability_age)
    &quot;&quot;&quot;,
    format=&quot;arrow&quot;,
)
df = response.to_pandas(types_mapper=pd.ArrowDtype)
print(df)</code></pre>
<p>Today, we have a limitation with ESQL: we can’t paginate through results. Therefore we are limited to 10K output documents (100K if server configuration is modified). Progress can be followed through this <a href="https://github.com/elastic/elasticsearch/issues/100000">enhancement request</a>.</p>
<h4 class="font-bold leading-tight text-lg md:text-2xl relative"><span id="with-dsl" class="absolute -top-32"></span>With DSL</h4>
<p>In the elasticsearch python client, there is a native feature to extract all the data from a query with transparent pagination. The challenging part is to create the DSL query. We recommend creating the query in Discover and then click on Inspect, and then Request tab to get the DSL query.</p>
<pre><code>query = {
    &quot;track_total_hits&quot;: True,
    &quot;query&quot;: {
        &quot;bool&quot;: {
            &quot;filter&quot;: [
                {
                    &quot;match&quot;: {
                        &quot;elastic.owner.team&quot;: &quot;awesome-sre-team&quot;
                    }
                },
                {
                    &quot;match&quot;: {
                        &quot;elastic.environment&quot;: &quot;production&quot;
                    }
                },
                {
                    &quot;match&quot;: {
&quot;qualys_vmdr.asset_host_detection.vulnerability.is_ignored&quot;: False
                    }
                }
            ]
        }
    },
    &quot;fields&quot;: [
        &quot;@timestamp&quot;,
        &quot;qualys_vmdr.asset_host_detection.vulnerability.unique_vuln_id&quot;,
        &quot;qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime&quot;,
        &quot;qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime&quot;,
        &quot;elastic.vulnerability.age&quot;,
        &quot;qualys_vmdr.asset_host_detection.vulnerability.status&quot;,
        &quot;vulnerability.severity&quot;,
        &quot;qualys_vmdr.asset_host_detection.vulnerability.is_ignored&quot;
    ],
    &quot;_source&quot;: False
}

results = list(scan(
        client=es,
        query=query,
        scroll=&#x27;30m&#x27;,
        index=source_index,
        size=10000,
        raise_on_error=True,
        preserve_order=False,
        clear_scroll=True
    ))</code></pre>
<h2 class="font-bold text-2xl md:text-4xl relative"><span id="survival-analysis" class="absolute -top-32"></span>Survival Analysis</h2>
<p>You can refer to the <a href="https://github.com/lauravoicu/elastic-vm-survivalanalysis/tree/main">code</a> to understand or reproduce it on your dataset.</p>
<h2 class="font-bold text-2xl md:text-4xl relative"><span id="what-we-learned" class="absolute -top-32"></span>What We Learned</h2>
<p>Leaning in on the research from the <a href="https://www.cyentia.com/why-your-mttr-is-probably-bogus/">Cyentia Institute</a> we looked at a few different ways to measure how long it takes to remediate vulnerabilities using means, medians, and survival curves. Each method gives a different lens through which we can understand time-to-patch data, and the comparison is important because depending on which method we use, we would draw very different conclusions about how well vulnerabilities are being addressed.</p>
<p>The first method focuses only on vulnerabilities that have already been closed. It calculates the median and mean time it took to patch them. This is intuitive and simple, but it leaves out a potentially large and important portion of the data (the vulnerabilities that are still open). As a result, it tends to underestimate the true time it takes to remediate, especially if some vulnerabilities stay open much longer than others.</p>
<p>The second method tries to include both closed and open vulnerabilities by using the time they’ve been open <em>so far</em>. There are many options to approximate a time-to-patch for the open vulnerabilities, but for simplicity here we assumed they were (will be?) patched at the time of reporting, which we know isn’t true. But it does offer a way to factor in their existence.</p>
<p>The third method uses survival analysis. Specifically, we used the Kaplan-Meier estimator to model the likelihood that a vulnerability is still open at any given time. This method handles the open vulnerabilities properly: instead of pretending they’re patched, it treats them as “censored” data. The survival curve it produces drops over time, showing the proportion of vulnerabilities still open as days or weeks pass.</p>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="how-long-do-vulnerabilities-last" class="absolute -top-32"></span>How Long Do Vulnerabilities Last?</h3>
<p></p>
<p>In the current 6-month snapshot[^2], the closed-only time-to-patch has a median ~33 days and a mean ~35 days. On the surface that looks reasonable, but the Kaplan-Meier curve shows what those numbers hide: at 33 days, ~54% are still open; at 35 days, ~46% are still open. So even around the “typical” one-month mark, about half of issues remain unresolved.</p>
<p>We also computed observed-so-far statistics (treating open vulnerabilities as if they were patched at the end of the measurement window). In this window they happen to be almost the same (median ~33 days, mean ~35 days) because the ages of today’s open items cluster near one month. That coincidence can make averages look reassuring, but it’s incidental and unstable: if we shift the snapshot to just before the monthly patch push and these same statistics drop sharply (we’ve seen an observed median of ~19 days and observed a mean of ~15 days) without any change in the underlying process.</p>
<p>The survival curve avoids that trap, because it answers the question of “% still open after 30/60/90 days”, and offers visibility into the long tail that stays open well past a month.</p>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="patch-everything-everywhere-the-same-way" class="absolute -top-32"></span>Patch Everything Everywhere The Same Way?</h3>
<p></p>
<p>Stratified survival analysis takes the idea of survival curves one step further. Instead of looking at all vulnerabilities together in one big pool, it separates them into groups (or “strata”) based on some meaningful characteristic. In our analysis, we have stratified vulnerabilities by severity, asset criticality, environment, cloud provider, team/division/organization. Each group gets its own survival curve, and here in the example graph we compare how quickly different vulnerability severities are remediated over time.</p>
<p>The benefit of this approach is that it exposes differences that would otherwise be hidden in the aggregate. If we only looked at the overall survival curve, we can only make conclusions about the remediation performance across the board. But stratification reveals if different teams, environments or severity issues are addressed faster than the rest, and in our case that the patch everything strategy is indeed consistent. This level of detail is important for making targeted improvements, helping us understand not just how long remediation takes in general, but if and where real bottlenecks exist.</p>
<h3 class="font-bold leading-tight text-xl md:text-3xl relative"><span id="how-fast-do-teams-act" class="absolute -top-32"></span>How Fast Do Teams Act?</h3>
<p></p>
<p>While the survival curve emphasizes how long vulnerabilities remain open, we can flip the perspective by using the cumulative distribution function (CDF) instead. The CDF focuses on how quickly vulnerabilities are patched, showing the proportion of vulnerabilities that have been remediated by a given point in time.</p>
<p>Our choice of plotting the CDF provides a clear picture of remediation speed, however it’s important to note that this version includes only vulnerabilities that were patched within the observed time window. Unlike the survival curve which we compute over a rolling 6-month cohort to capture full lifecycles, the CDF is computed month-over-month on items closed in that month[^3].</p>
<p>As such, it tells us how quickly teams remediate vulnerabilities <strong>once they do so</strong>, and it doesn’t reflect how long unresolved vulnerabilities remain open. For example, we see that 83.2% of the vulnerabilities closed in the current month were resolved within 30 days of the first detection. This highlights patching velocity for recent, successful patches but does not account for longer-standing vulnerabilities that remain open and are likely to have longer time-to-patch durations. Therefore, we use the CDF for understanding short-term response behavior, whereas the full lifecycle dynamics are given by a combination of CDF alongside survival analysis: the CDF describes <em>how fast teams act</em> once they patch, whereas the survival curve shows <em>how long vulnerabilities truly last</em>.</p>
<h2 class="font-bold text-2xl md:text-4xl relative"><span id="difference-between-survival-analysis-and-meanmedian" class="absolute -top-32"></span>Difference Between Survival Analysis and Mean/Median</h2>
<p>Wait, we said that survival analysis is better to analyze time to patch to avoid the impact of outliers. But in this example, mean/median and survival analysis provide similar results. What is the added value? The reason is simple: we don’t have outliers in our production environments since our patching process is fully automated and effective.</p>
<p>To demonstrate the impact on heterogeneous data, we’ll use an outdated example from a non-production environment that lacks automated patching.</p>
<p>ESQL query:</p>
<pre><code>FROM qualys_vmdr.vulnerability_6months
  | WHERE elastic.environment == &quot;my-outdated-non-production-environment&quot;
  | WHERE qualys_vmdr.asset_host_detection.vulnerability.is_ignored == FALSE
  | EVAL vulnerability_age = DATE_DIFF(&quot;day&quot;, qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime, qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime)
  | STATS
      count=COUNT(*),
      count_closed_only=COUNT(*) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == &quot;Fixed&quot;,
      mean_observed_so_far=MEDIAN(vulnerability_age),
      mean_closed_only=MEDIAN(vulnerability_age) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == &quot;Fixed&quot;,
      median_observed_so_far=MEDIAN(vulnerability_age),
      median_closed_only=MEDIAN(vulnerability_age) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == &quot;Fixed&quot;</code></pre>
<div class="table-container"><table style="width:100%;table-layout:fixed;word-wrap:break-word"><thead><tr><th style="text-align:left"></th><th style="text-align:left">Observed so far</th><th style="text-align:left">Closed only</th></tr></thead><tbody><tr><td style="text-align:left">Count</td><td style="text-align:left">833</td><td style="text-align:left">322</td></tr><tr><td style="text-align:left">Mean</td><td style="text-align:left">178.7 (days)</td><td style="text-align:left">163.8 (days)</td></tr><tr><td style="text-align:left">Median</td><td style="text-align:left">61 (days)</td><td style="text-align:left">5 (days)</td></tr><tr><td style="text-align:left">Median survival</td><td style="text-align:left">527 (days)</td><td style="text-align:left">N/A</td></tr></tbody></table></div>
<p></p>
<p>In this example, using mean and median yield very different results. Choosing a single representative metric can be challenging and potentially misleading. The survival analysis graph accurately represents our effectiveness in addressing vulnerabilities within this environment.</p>
<h2 class="font-bold text-2xl md:text-4xl relative"><span id="final-thoughts" class="absolute -top-32"></span>Final Thoughts</h2>
<p>The benefits of using survival analysis come not only from more accurate measurement but also from the insights into the dynamics of patching behaviour, showing where bottlenecks occur, factors that affect patching velocity and whether it aligns with our SLO. From a technical integration perspective, the use of survival analysis as part of our operational workflows and reporting can be achieved with minimal additional changes to our current Elastic Stack setup: survival analysis can run on the same cadence as our patching cycle with the results being pushed back into Kibana for visualization. The definitive advantage is to pair our existing operational metrics with survival analysis for both long-term trends and short-term performance tracking.</p>
<p>Looking forward, we’re experimenting with additional new metrics like <strong>Arrival Rate</strong>, <strong>Burndown Rate</strong>, and <strong>Escape Rate</strong> that give us a way to move toward a more dynamic understanding of how vulnerabilities are really handled.</p>
<p><strong>Arrival Rate</strong> is the measure of how quickly new vulnerabilities are entering the environment. Knowing that fifty new CVEs show up each month, for example, tells us what to expect in the workload before we even start measuring patches. So the arrival rate is a metric that does not necessarily inform about the backlog, but more about the pressure applied to the system.</p>
<p><strong>Burndown Rate</strong> (trend) shows the other half of the equation: how quickly vulnerabilities are being remediated relative to how fast they arrive.</p>
<p><strong>Escape Rate</strong> adds yet another dimension by focusing on vulnerabilities that slip past the points where they should have been contained. In our context, an escape is about CVEs that miss patching windows or exceed SLO thresholds. An elevated escape rate doesn’t just show that vulnerabilities exist but it also shows that the process designed to control them is failing, whether because patching cycles are too slow, automation processes are lacking, or compensating controls are not working as intended.</p>
<p>Together, the metrics create a better picture: arrival rate tells us how much new risk is being introduced; burndown trends show whether we are keeping pace with that pressure or being overwhelmed by it; escape rates expose where vulnerabilities persist despite planned controls.</p>
<p>[1]:An outlier in statistics is a data point that is very far from the central tendency (or far from the rest of the values in a dataset). For example, if most vulnerabilities are patched within 30 days, but one takes 600 days, that 600-day case is an outlier. Outliers can pull averages upward or downward in ways that don’t reflect the “typical” experience. In the patching context, these are the especially slow-to-patch vulnerabilities that sit open far longer than the norm. They may represent rare but important situations, like systems that can’t be easily updated, or patches that require extensive testing.</p>
<p>[2]: Note: The current 6-month dataset includes both all vulnerabilities that remain open at the end of the observation period (independent of how long ago they have been open /first seen) and all vulnerabilities that were closed during the 6-month window. Despite this mixed cohort approach, survival curves from prior observation windows show consistent trends, particularly in the early part of the curve. The shape and slope over the first 30–60 days have proven remarkably stable across snapshots, suggesting that metrics like median time-to-patch and early-stage remediation behavior are not artifacts of the short observation window. While long-term estimates (e.g. 90th percentile) remain incomplete in shorter snapshots, the conclusions drawn from these cohorts still reflect persistent and reliable patching dynamics.</p>
<p>[3]:We kept the CDF on a monthly cadence for operational reporting (throughput and SLO adherence for work completed during the current month), while the Kaplan-Meier uses a 6-month window to properly handle censoring and expose tail risk across the broader cohort.</p></div></div></div><div class="hidden lg:flex lg:col-span-1 text-sm lg:flex-col lg:space-y-6"><div class="toc"><h4 class="font-bold leading-tight text-lg md:text-2xl mb-3">Jump to section</h4><ul class="flex flex-col space-y-2"><li><a class="flex items-center space-x-1 hover:text-white" href="/security-labs/time-to-patch-metrics#introduction"><span>Introduction</span></a></li><li><a class="flex items-center space-x-1 hover:text-white ml-4" href="/security-labs/time-to-patch-metrics#why-we-did-it"><span>Why We Did&nbsp;It</span></a></li><li><a class="flex items-center space-x-1 hover:text-white ml-4" href="/security-labs/time-to-patch-metrics#why-survival-analysis-a-better-alternative-to-mean-time-to-remediate"><span>Why Survival Analysis? A Better Alternative to Mean Time to&nbsp;Remediate</span></a></li><li><a class="flex items-center space-x-1 hover:text-white" href="/security-labs/time-to-patch-metrics#context"><span>Context</span></a></li><li><a class="flex items-center space-x-1 hover:text-white ml-4" href="/security-labs/time-to-patch-metrics#vulnerability-age-calculation"><span>Vulnerability age&nbsp;calculation</span></a></li><li><a class="flex items-center space-x-1 hover:text-white ml-4" href="/security-labs/time-to-patch-metrics#patch-everything-strategy"><span>“Patch everything”&nbsp;strategy</span></a></li><li><a class="flex items-center space-x-1 hover:text-white" href="/security-labs/time-to-patch-metrics#data-pipeline"><span>Data&nbsp;Pipeline</span></a></li><li><a class="flex items-center space-x-1 hover:text-white ml-4" href="/security-labs/time-to-patch-metrics#qualys-agent-integration-configuration"><span>Qualys agent integration&nbsp;configuration</span></a></li><li><a class="flex items-center space-x-1 hover:text-white ml-4" href="/security-labs/time-to-patch-metrics#loading-data-into-python-with-the-elasticsearch-client"><span>Loading data into Python with the elasticsearch&nbsp;client</span></a></li><li><a class="flex items-center space-x-1 hover:text-white ml-8" href="/security-labs/time-to-patch-metrics#with-esql"><span>With&nbsp;ES|QL</span></a></li></ul><button class="border-t border-white/20 w-full mt-3 py-2 flex items-center space-x-1 text-xs font-medium uppercase tracking-wide hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" aria-hidden="true" class="w-3 h-3"><path d="M10.75 4.75a.75.75 0 00-1.5 0v4.5h-4.5a.75.75 0 000 1.5h4.5v4.5a.75.75 0 001.5 0v-4.5h4.5a.75.75 0 000-1.5h-4.5v-4.5z"></path></svg><span>Show more</span></button></div><div class="bg-zinc-900 border border-zinc-800 drop-shadow-lg p-5 md:p-2 sm:p-4 md:px-6 md:py-4 rounded-xl"><h4 class="font-bold leading-tight text-lg md:text-2xl mb-3">Elastic Security Labs Newsletter</h4><div><a target="_blank" class="button inline-flex" href="https://www.elastic.co/elastic-security-labs/newsletter?utm_source=security-labs">Sign Up</a></div></div></div></div><div class="bg-zinc-900 border border-zinc-800 drop-shadow-lg p-5 md:p-2 sm:p-4 md:px-6 md:py-4 rounded-xl my-5 md:my-10 max-w-3xl mx-auto flex flex-col items-center shadow-2xl"><h4 class="font-bold leading-tight text-lg md:text-2xl">Share this article</h4><div class="flex flex-wrap items-center justify-center mt-4 space-x-4"><a class="flex items-center space-x-2 button" href="https://twitter.com/intent/tweet?text=Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic&amp;url=https://www.elastic.co/security-labs/time-to-patch-metrics" target="_blank" rel="noopener noreferrer" aria-label="Share this article on X" title="Share this article on X"><svg class="w-4 h-4" viewBox="0 0 24 24"><path fill="currentColor" d="M23.954 4.569c-.885.389-1.83.653-2.825.772a4.98 4.98 0 002.187-2.746 9.955 9.955 0 01-3.157 1.204 4.98 4.98 0 00-8.49 4.54A14.128 14.128 0 011.69 3.05a4.98 4.98 0 001.54 6.638A4.94 4.94 0 011.2 8.62v.06a4.98 4.98 0 004 4.87 4.94 4.94 0 01-2.24.086 4.98 4.98 0 004.64 3.45A9.97 9.97 0 010 20.35a14.075 14.075 0 007.59 2.22c9.16 0 14.17-7.583 14.17-14.17 0-.217-.005-.434-.015-.65a10.128 10.128 0 002.485-2.58l-.001-.001z"></path></svg><span>X</span></a><a class="flex items-center space-x-2 button" href="https://www.facebook.com/sharer/sharer.php?u=https://www.elastic.co/security-labs/time-to-patch-metrics" target="_blank" rel="noopener noreferrer" aria-label="Share this article on Facebook" title="Share this article on Facebook"><svg class="w-4 h-4" viewBox="0 0 24 24"><path fill="currentColor" d="M22.5 12c0-5.799-4.701-10.5-10.5-10.5S1.5 6.201 1.5 12c0 5.301 3.901 9.699 9 10.401V14.4h-2.7v-2.7h2.7v-2.1c0-2.7 1.8-4.2 4.2-4.2 1.2 0 2.1.1 2.4.2v2.4h-1.5c-1.2 0-1.5.6-1.5 1.5v1.8h3l-.3 2.7h-2.7V22C18.599 21.3 22.5 17.301 22.5 12z"></path></svg><span>Facebook</span></a><a class="flex items-center space-x-2 button" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.elastic.co/security-labs/time-to-patch-metrics&amp;title=Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic" target="_blank" rel="noopener noreferrer" aria-label="Share this article on LinkedIn" title="Share this article on LinkedIn"><svg class="w-4 h-4" viewBox="0 0 24 24"><path fill="currentColor" d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"></path></svg><span>LinkedIn</span></a><a class="flex items-center space-x-2 button" href="https://reddit.com/submit?url=https://www.elastic.co/security-labs/time-to-patch-metrics&amp;title=Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic" target="_blank" rel="noopener noreferrer" aria-label="Share this article on Reddit" title="Share this article on Reddit"><svg class="w-4 h-4" viewBox="0 0 24 24"><path fill-rule="evenodd" clip-rule="evenodd" d="M24 12C24 18.6274 18.6274 24 12 24C5.37258 24 0 18.6274 0 12C0 5.37258 5.37258 0 12 0C18.6274 0 24 5.37258 24 12ZM19.6879 11.0584C19.8819 11.3352 19.9916 11.6622 20.004 12C20.0091 12.3306 19.9205 12.656 19.7485 12.9384C19.5765 13.2208 19.3281 13.4488 19.032 13.596C19.0455 13.7717 19.0455 13.9483 19.032 14.124C19.032 16.812 15.9 18.996 12.036 18.996C8.172 18.996 5.04 16.812 5.04 14.124C5.02649 13.9483 5.02649 13.7717 5.04 13.596C4.80919 13.49 4.6042 13.335 4.43923 13.1419C4.27427 12.9487 4.15327 12.722 4.08462 12.4775C4.01598 12.2329 4.00133 11.9764 4.04169 11.7256C4.08205 11.4748 4.17646 11.2358 4.31837 11.0251C4.46028 10.8145 4.6463 10.6372 4.86354 10.5056C5.08078 10.3739 5.32404 10.2911 5.57646 10.2629C5.82889 10.2346 6.08444 10.2616 6.32541 10.3419C6.56638 10.4222 6.78701 10.5539 6.972 10.728C8.35473 9.79023 9.98146 9.27718 11.652 9.252L12.54 5.088C12.55 5.03979 12.5694 4.99405 12.5972 4.95341C12.625 4.91277 12.6605 4.87805 12.7018 4.85127C12.7431 4.82448 12.7894 4.80615 12.8378 4.79735C12.8862 4.78855 12.9359 4.78945 12.984 4.8L15.924 5.388C16.0676 5.14132 16.2944 4.9539 16.5637 4.85937C16.833 4.76484 17.1272 4.7694 17.3934 4.87222C17.6597 4.97505 17.8806 5.1694 18.0164 5.42041C18.1523 5.67141 18.1942 5.96262 18.1348 6.24177C18.0753 6.52092 17.9182 6.76972 17.6918 6.94352C17.4654 7.11732 17.1845 7.20473 16.8995 7.19006C16.6144 7.1754 16.3439 7.05962 16.1366 6.8635C15.9292 6.66738 15.7985 6.40378 15.768 6.12L13.2 5.58L12.42 9.324C14.0702 9.3594 15.6749 9.87206 17.04 10.8C17.2839 10.566 17.5902 10.4074 17.9221 10.3436C18.254 10.2797 18.5973 10.3132 18.9106 10.4401C19.2239 10.5669 19.4939 10.7817 19.6879 11.0584ZM8.20624 12.5333C8.07438 12.7307 8.004 12.9627 8.004 13.2C8.004 13.5183 8.13043 13.8235 8.35547 14.0485C8.58051 14.2736 8.88574 14.4 9.204 14.4C9.44134 14.4 9.67335 14.3296 9.87068 14.1978C10.068 14.0659 10.2218 13.8785 10.3127 13.6592C10.4035 13.4399 10.4272 13.1987 10.3809 12.9659C10.3346 12.7331 10.2204 12.5193 10.0525 12.3515C9.8847 12.1836 9.67089 12.0694 9.43811 12.0231C9.20533 11.9768 8.96405 12.0005 8.74478 12.0913C8.52551 12.1822 8.33809 12.336 8.20624 12.5333ZM12.012 17.424C13.0771 17.4681 14.1246 17.1416 14.976 16.5V16.548C15.0075 16.5173 15.0327 16.4806 15.05 16.4402C15.0674 16.3997 15.0766 16.3563 15.0772 16.3122C15.0777 16.2682 15.0696 16.2245 15.0533 16.1837C15.0369 16.1428 15.0127 16.1055 14.982 16.074C14.9513 16.0425 14.9146 16.0173 14.8742 16C14.8337 15.9826 14.7903 15.9734 14.7462 15.9728C14.7022 15.9723 14.6585 15.9804 14.6177 15.9967C14.5768 16.0131 14.5395 16.0373 14.508 16.068C13.7797 16.5904 12.895 16.8487 12 16.8C11.1061 16.8399 10.2255 16.5732 9.504 16.044C9.44182 15.993 9.36289 15.9669 9.28256 15.9708C9.20222 15.9748 9.12622 16.0085 9.06935 16.0653C9.01247 16.1222 8.97879 16.1982 8.97484 16.2786C8.97089 16.3589 8.99697 16.4378 9.048 16.5C9.89937 17.1416 10.9469 17.4681 12.012 17.424ZM14.0933 14.2458C14.2907 14.3776 14.5227 14.448 14.76 14.448L14.748 14.496C14.9107 14.4978 15.0721 14.4664 15.2223 14.4038C15.3725 14.3413 15.5084 14.2488 15.6218 14.1321C15.7352 14.0154 15.8236 13.8768 15.8818 13.7248C15.9399 13.5728 15.9665 13.4106 15.96 13.248C15.96 13.0107 15.8896 12.7787 15.7578 12.5813C15.6259 12.384 15.4385 12.2302 15.2192 12.1393C14.9999 12.0485 14.7587 12.0248 14.5259 12.0711C14.2931 12.1174 14.0793 12.2316 13.9115 12.3995C13.7436 12.5673 13.6294 12.7811 13.5831 13.0139C13.5368 13.2467 13.5605 13.4879 13.6513 13.7072C13.7422 13.9265 13.896 14.1139 14.0933 14.2458Z" fill="currentColor"></path></svg><span>Reddit</span></a></div></div></article></main><footer class="mt-auto text-xs md:text-sm"><div class="container py-6 flex flex-col md:flex-row gap-2 md:gap-0 justify-between items-center"><div class="text-zinc-300"><nav><ul class="flex space-x-4"><li><a class="hover:text-white font-medium" href="/security-labs/sitemap.xml">Sitemap</a></li><li><a class="hover:text-white font-medium flex items-center space-x-1" href="https://elastic.co?utm_source=elastic-search-labs&amp;utm_medium=referral&amp;utm_campaign=search-labs&amp;utm_content=footer"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="inline-block w-3 h-3"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 003 8.25v10.5A2.25 2.25 0 005.25 21h10.5A2.25 2.25 0 0018 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg><span>Elastic.co</span></a></li><li><a class="hover:text-white font-medium flex items-center space-x-1" href="https://twitter.com/elasticseclabs"><svg class="w-4 h-4 inline-block w-3 h-3" viewBox="0 0 24 24"><path fill="currentColor" d="M23.954 4.569c-.885.389-1.83.653-2.825.772a4.98 4.98 0 002.187-2.746 9.955 9.955 0 01-3.157 1.204 4.98 4.98 0 00-8.49 4.54A14.128 14.128 0 011.69 3.05a4.98 4.98 0 001.54 6.638A4.94 4.94 0 011.2 8.62v.06a4.98 4.98 0 004 4.87 4.94 4.94 0 01-2.24.086 4.98 4.98 0 004.64 3.45A9.97 9.97 0 010 20.35a14.075 14.075 0 007.59 2.22c9.16 0 14.17-7.583 14.17-14.17 0-.217-.005-.434-.015-.65a10.128 10.128 0 002.485-2.58l-.001-.001z"></path></svg><span>@elasticseclabs</span></a></li></ul></nav></div><div class="flex flex-col space-y-1 text-zinc-300"><p>© <!-- -->2025<!-- -->. Elasticsearch B.V. All Rights Reserved.</p></div></div></footer></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"article":{"title":"Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic","slug":"time-to-patch-metrics","date":"2025-10-22","description":"In this article, we describe how we applied survival analysis to vulnerability management (VM) data from Qualys VMDR, using the Elastic Stack.","image":"Security Labs Images 7.jpg","tags":["qualys","vulnerability"],"body":{"raw":"\n# Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic \n\n## Introduction\n\nUnderstanding how quickly vulnerabilities are remediated across different environments and teams is critical to maintaining a strong security posture. In this article, we describe how we applied **survival analysis** to vulnerability management (VM) data from **Qualys VMDR**, using the **Elastic Stack**. This allowed us to not only confirm general assumptions about team velocity (how quickly teams complete work) and remediation capacity (how much fixing they can take on) but also derive measurable insights. Since most of our security data is in the Elastic Stack, this process should be easily reproducible to other security data sources. \n\n### Why We Did It\n\nOur primary motivation was to **move from general assumptions to data-backed insights** about:\n\n* How quickly different teams and environments patch vulnerabilities  \n* Whether patching performance meets internal service level objectives (SLOs)  \n* Where bottlenecks or delays commonly occur  \n* What other factors can affect patching performance\n\n### Why Survival Analysis? A Better Alternative to Mean Time to Remediate\n\nMean Time to Remediate (MTTR) is commonly used to track how quickly vulnerabilities are patched, but both the mean and median suffer from significant limitations (we provide an example later in this article). The mean is highly sensitive to *outliers*[^1] and assumes the remediation times are evenly balanced around the average remediation time, which is rarely the case in practice. The median is less sensitive to extremes but discards information about the shape of the distribution and says nothing about the long tail of slow-to-patch vulnerabilities. Neither accounts for unresolved cases, i.e. vulnerabilities that remain open beyond the observation window, which are often excluded entirely. In practice, the vulnerabilities that remain open the longest are precisely the ones we should be most concerned about.\n\n**Survival analysis** addresses these limitations. Originating in medical and actuarial contexts, it models **time-to-event data** while explicitly incorporating **censored observations**, meaning in our context vulnerabilities that remain open. (For more details on its application to vulnerability management we strongly recommend [“The Metrics Manifesto”](https://www.themetricsmanifesto.com)). Instead of collapsing remediation behavior into a single number, survival analysis estimates the probability that a vulnerability remains unpatched over time (e.g. 90% of vulnerabilities are remediated within 30 days). This allows for more meaningful assessments, such as the proportion of vulnerabilities patched within SLO (for example within 30, 90, or 180 days).\n\nSurvival analysis provides us with a **survival function** that estimates the probability a vulnerability remains unpatched over time.\n\n::: \nThis method offers a better view of remediation performance, allowing us to assess not just how long vulnerabilities persist, but also how remediation behavior differs across systems, teams, or severity levels. It’s particularly well-suited to security data, which is often incomplete, skewed, and resistant to assumptions of normality.\n:::\n\n## Context\n\nAlthough we have applied survival analysis across different environments, teams and organizations, in this blog we focus on the results for the Elastic Cloud production environment. \n\n### Vulnerability age calculation\n\nThere are different methods to calculate vulnerability age.\n\nFor our internal metrics like [vulnerability adherence SLO](https://www.elastic.co/blog/how-infosec-uses-elastic-stack-vulnerability-management), we define vulnerability age as the difference between when a vulnerability was last found and when it was first detected (usually a few days after publication). This approach aims to penalize vulnerabilities that are reintroduced from an outdated base image. In the past, our base images were not updated frequently enough for our satisfaction. If a new instance is created, vulnerabilities can have a significant age (e.g., 100 days) from day one of discovery.\n\nFor this analysis, we find it more relevant to calculate the age based on the number of days between the last found date and the first found date. In this case, age represents the number of days the system was effectively exposed.\n\n### “Patch everything” strategy\n\nIn our Cloud environment, we maintain a policy to patch everything. This is because we almost exclusively use the same base image across all instances. Since Elastic Cloud operates fully on containers, there are no specific application packages (e.g., Elasticsearch) installed directly on our systems. Our fleet remains homogeneous as a result. \n\n## Data Pipeline\n\nIngesting and mapping data into the Elastic Stack can be cumbersome. Luckily, we have [many security integrations](https://www.elastic.co/integrations/data-integrations?solution=all-solutions\u0026category=security) that handle those natively, [Qualys VMDR](https://www.elastic.co/docs/reference/integrations/qualys_vmdr) being one of them.  \n\nThis integration has 3 main interests over custom ingestion methods (e.g. scripts, beats, …):\n\n* It natively enriches vulnerability data from the Qualys Knowledge Base which add CVE IDs, threat intel information, … **without needing to configure enrich pipelines**.  \n* Qualys data is already mapped to the Elastic Common Schema which is a standardized way of representing data, whether it’s coming from one source or another: for example, CVEs are always stored in field [*vulnerability.id*](http://vulnerability.id), independent of the source.   \n* A transform with the latest vulnerability is already set up. This index can be queried to get the latest vulnerabilities status. \n\n### Qualys agent integration configuration\n\nFor survival analysis, we need to ingest both active and patched vulnerabilities. To analyze a specific period, we need to set the number of days in field `max_days_since_detection_updated`. In our environment, we ingest Qualys data daily, so there’s no need to ingest a long history of fixed data, as we’ve already done that.  \n   \nThe Qualys VMDR elastic agent integration has been configured with the following:\n\n| Property | Value | Comment |\n| :---- | :---- | :---- |\n| (Settings section) Username |  |  |\n| (Settings section) Password |  | Since there are no API keys available in Qualys, we can only authenticate with Basic Authentication.  Make sure SSO is disabled on this account |\n| URL | [https://qualysapi.qg2.apps.qualys.com](https://qualysapi.qg2.apps.qualys.com) (for US2) | [https://www.qualys.com/platform-identification/](https://www.qualys.com/platform-identification/)  |\n| Interval | 4h | Adjust it based on the number of ingested events.  |\n| Input parameters | show_asset_id=1\u0026 include_vuln_type=confirmed\u0026show_results=1\u0026max_days_since_detection_updated=3\u0026status=New,Active,Re-Opened,Fixed\u0026filter_superseded_qids=1\u0026use_tags=1\u0026tag_set_by=name\u0026tag_include_selector=all\u0026tag_exclude_selector=any\u0026tag_set_include=status:running\u0026tag_set_exclude=status:terminated,status:stopped,status:stale\u0026show_tags=1\u0026show_cloud_tags=1 | show_asset_id=1: retrieve asset id show_results=1: details about what is the current installed package and which version should be installed max_days_since_detection_updated=3: filter out any vulnerabilities that haven’t been updated over the last 3 days (e.g. patched older than 3 days) status=New,Active,Re-Opened,Fixed: all vulnerability status are ingested filter_superseded_qids=1: ignore superseded ‘vulnerabilities Tags: filter by tags show_tags=1: retrieve Qualys tags show_cloud_tags=1: retrieve Cloud tags |\n\nOnce data is fully ingested, it can be reviewed either in Kibana Discover (logs-* data view -\u003e *data_stream.dataset : \"qualys_vmdr.asset_host_detection\"* ), either in the Kibana Security App (Findings -\u003e Vulnerabilities).\n\n![](/assets/images/time-to-patch-metrics/image6.png)\n\n### Loading data into Python with the elasticsearch client\n\nSince the survival analysis calculation will be done in Python, we need to extract data from elastic into a python dataframe. There are several ways to achieve this, and in this article we’ll focus on two of them.\n\n#### With ES|QL\n\nThe easiest and most convenient way is to leverage ES|QL with the arrow format. It’ll automatically populate the python dataframe (rows and columns). We recommend reading the blog post [From ES|QL to native Pandas dataframes in Python](https://www.elastic.co/search-labs/blog/esql-pandas-native-dataframes-python) to get more details.  \n\n```py\nfrom elasticsearch import Elasticsearch\nimport pandas as pd\n\nclient = Elasticsearch(\n    \"https://[host].elastic-cloud.com\",\n    api_key=\"...\",\n)\n\nresponse = client.esql.query(\n    query=\"\"\"\n   FROM logs-qualys_vmdr.asset_host_detection-default\n    | WHERE elastic.owner.team == \"platform-security\" AND elastic.environment == \"production\"\n    | WHERE qualys_vmdr.asset_host_detection.vulnerability.is_ignored == FALSE\n    | EVAL vulnerability_age = DATE_DIFF(\"day\", qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime, qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime)\n    | STATS \n        mean=AVG(vulnerability_age), \n        median=MEDIAN(vulnerability_age)\n    \"\"\",\n    format=\"arrow\",\n)\ndf = response.to_pandas(types_mapper=pd.ArrowDtype)\nprint(df)\n```\n   \nToday, we have a limitation with ESQL: we can’t paginate through results. Therefore we are limited to 10K output documents (100K if server configuration is modified). Progress can be followed through this [enhancement request](https://github.com/elastic/elasticsearch/issues/100000). \n\n#### With DSL\n\nIn the elasticsearch python client, there is a native feature to extract all the data from a query with transparent pagination. The challenging part is to create the DSL query. We recommend creating the query in Discover and then click on Inspect, and then Request tab to get the DSL query. \n\n```py\nquery = {\n    \"track_total_hits\": True,\n    \"query\": {\n        \"bool\": {\n            \"filter\": [\n                {\n                    \"match\": {\n                        \"elastic.owner.team\": \"awesome-sre-team\"\n                    }\n                },\n                {\n                    \"match\": {\n                        \"elastic.environment\": \"production\"\n                    }\n                },\n                {\n                    \"match\": {\n\"qualys_vmdr.asset_host_detection.vulnerability.is_ignored\": False\n                    }\n                }\n            ]\n        }\n    },\n    \"fields\": [\n        \"@timestamp\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.unique_vuln_id\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime\",\n        \"elastic.vulnerability.age\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.status\",\n        \"vulnerability.severity\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.is_ignored\"\n    ],\n    \"_source\": False\n}\n\nresults = list(scan(\n        client=es,\n        query=query,\n        scroll='30m',\n        index=source_index,\n        size=10000,\n        raise_on_error=True,\n        preserve_order=False,\n        clear_scroll=True\n    ))\n```\n\n## Survival Analysis\n\nYou can refer to the [code](https://github.com/lauravoicu/elastic-vm-survivalanalysis/tree/main) to understand or reproduce it on your dataset. \n\n## What We Learned\n\nLeaning in on the research from the [Cyentia Institute](https://www.cyentia.com/why-your-mttr-is-probably-bogus/) we looked at a few different ways to measure how long it takes to remediate vulnerabilities using means, medians, and survival curves. Each method gives a different lens through which we can understand time-to-patch data, and the comparison is important because depending on which method we use, we would draw very different conclusions about how well vulnerabilities are being addressed.\n\nThe first method focuses only on vulnerabilities that have already been closed. It calculates the median and mean time it took to patch them. This is intuitive and simple, but it leaves out a potentially large and important portion of the data (the vulnerabilities that are still open). As a result, it tends to underestimate the true time it takes to remediate, especially if some vulnerabilities stay open much longer than others.\n\nThe second method tries to include both closed and open vulnerabilities by using the time they’ve been open *so far*. There are many options to approximate a time-to-patch for the open vulnerabilities, but for simplicity here we assumed they were (will be?) patched at the time of reporting, which we know isn’t true. But it does offer a way to factor in their existence.\n\nThe third method uses survival analysis. Specifically, we used the Kaplan-Meier estimator to model the likelihood that a vulnerability is still open at any given time. This method handles the open vulnerabilities properly: instead of pretending they’re patched, it treats them as “censored” data. The survival curve it produces drops over time, showing the proportion of vulnerabilities still open as days or weeks pass. \n\n### How Long Do Vulnerabilities Last?\n\n![](/assets/images/time-to-patch-metrics/image4.png)\n\nIn the current 6-month snapshot[^2], the closed-only time-to-patch has a median \\~33 days and a mean \\~35 days. On the surface that looks reasonable, but the Kaplan-Meier curve shows what those numbers hide: at 33 days, \\~54% are still open; at 35 days, \\~46% are still open. So even around the “typical” one-month mark, about half of issues remain unresolved.\n\nWe also computed observed-so-far statistics (treating open vulnerabilities as if they were patched at the end of the measurement window). In this window they happen to be almost the same (median \\~33 days, mean \\~35 days) because the ages of today’s open items cluster near one month. That coincidence can make averages look reassuring, but it’s incidental and unstable: if we shift the snapshot to just before the monthly patch push and these same statistics drop sharply (we’ve seen an observed median of \\~19 days and observed a mean of \\~15 days) without any change in the underlying process.\n\nThe survival curve avoids that trap, because it answers the question of “% still open after 30/60/90 days”, and offers visibility into the long tail that stays open well past a month.\n\n### Patch Everything Everywhere The Same Way?\n\n![](/assets/images/time-to-patch-metrics/image5.png)\n\n\nStratified survival analysis takes the idea of survival curves one step further. Instead of looking at all vulnerabilities together in one big pool, it separates them into groups (or “strata”) based on some meaningful characteristic. In our analysis, we have stratified vulnerabilities by severity, asset criticality, environment, cloud provider, team/division/organization. Each group gets its own survival curve, and here in the example graph we compare how quickly different vulnerability severities are remediated over time.\n\nThe benefit of this approach is that it exposes differences that would otherwise be hidden in the aggregate. If we only looked at the overall survival curve, we can only make conclusions about the remediation performance across the board. But stratification reveals if different teams, environments or severity issues are addressed faster than the rest, and in our case that the patch everything strategy is indeed consistent. This level of detail is important for making targeted improvements, helping us understand not just how long remediation takes in general, but if and where real bottlenecks exist.\n\n### How Fast Do Teams Act?\n\n![](/assets/images/time-to-patch-metrics/image2.png)\n\nWhile the survival curve emphasizes how long vulnerabilities remain open, we can flip the perspective by using the cumulative distribution function (CDF) instead. The CDF focuses on how quickly vulnerabilities are patched, showing the proportion of vulnerabilities that have been remediated by a given point in time.\n\nOur choice of plotting the CDF provides a clear picture of remediation speed, however it’s important to note that this version includes only vulnerabilities that were patched within the observed time window. Unlike the survival curve which we compute over a rolling 6-month cohort to capture full lifecycles, the CDF is computed month-over-month on items closed in that month[^3]. \n\nAs such, it tells us how quickly teams remediate vulnerabilities **once they do so**, and it doesn’t reflect how long unresolved vulnerabilities remain open. For example, we see that 83.2% of the vulnerabilities closed in the current month were resolved within 30 days of the first detection. This highlights patching velocity for recent, successful patches but does not account for longer-standing vulnerabilities that remain open and are likely to have longer time-to-patch durations. Therefore, we use the CDF for understanding short-term response behavior, whereas the full lifecycle dynamics are given by a combination of CDF alongside survival analysis: the CDF describes *how fast teams act* once they patch, whereas the survival curve shows *how long vulnerabilities truly last*.\n\n## Difference Between Survival Analysis and Mean/Median\n\nWait, we said that survival analysis is better to analyze time to patch to avoid the impact of outliers. But in this example, mean/median and survival analysis provide similar results. What is the added value? The reason is simple: we don’t have outliers in our production environments since our patching process is fully automated and effective.\n\nTo demonstrate the impact on heterogeneous data, we’ll use an outdated example from a non-production environment that lacks automated patching. \n\nESQL query:\n\n```sql\nFROM qualys_vmdr.vulnerability_6months\n  | WHERE elastic.environment == \"my-outdated-non-production-environment\"\n  | WHERE qualys_vmdr.asset_host_detection.vulnerability.is_ignored == FALSE\n  | EVAL vulnerability_age = DATE_DIFF(\"day\", qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime, qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime)\n  | STATS\n      count=COUNT(*),\n      count_closed_only=COUNT(*) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == \"Fixed\",\n      mean_observed_so_far=MEDIAN(vulnerability_age),\n      mean_closed_only=MEDIAN(vulnerability_age) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == \"Fixed\",\n      median_observed_so_far=MEDIAN(vulnerability_age),\n      median_closed_only=MEDIAN(vulnerability_age) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == \"Fixed\"\n```\n\n|  | Observed so far | Closed only |\n| :---- | :---- | :---- |\n| Count | 833 | 322 |\n| Mean | 178.7 (days) | 163.8 (days) |\n| Median | 61 (days) | 5 (days) |\n| Median survival | 527 (days) | N/A |\n\n![](/assets/images/time-to-patch-metrics/image1.png)\n\nIn this example, using mean and median yield very different results. Choosing a single representative metric can be challenging and potentially misleading. The survival analysis graph accurately represents our effectiveness in addressing vulnerabilities within this environment. \n\n## Final Thoughts\n\nThe benefits of using survival analysis come not only from more accurate measurement but also from the insights into the dynamics of patching behaviour, showing where bottlenecks occur, factors that affect patching velocity and whether it aligns with our SLO. From a technical integration perspective, the use of survival analysis as part of our operational workflows and reporting can be achieved with minimal additional changes to our current Elastic Stack setup: survival analysis can run on the same cadence as our patching cycle with the results being pushed back into Kibana for visualization. The definitive advantage is to pair our existing operational metrics with survival analysis for both long-term trends and short-term performance tracking.  \n\nLooking forward, we’re experimenting with additional new metrics like **Arrival Rate**, **Burndown Rate**, and **Escape Rate** that give us a way to move toward a more dynamic understanding of how vulnerabilities are really handled. \n\n**Arrival Rate** is the measure of how quickly new vulnerabilities are entering the environment. Knowing that fifty new CVEs show up each month, for example, tells us what to expect in the workload before we even start measuring patches. So the arrival rate is a metric that does not necessarily inform about the backlog, but more about the pressure applied to the system.\n\n**Burndown Rate** (trend) shows the other half of the equation: how quickly vulnerabilities are being remediated relative to how fast they arrive. \n\n**Escape Rate** adds yet another dimension by focusing on vulnerabilities that slip past the points where they should have been contained. In our context, an escape is about CVEs that miss patching windows or exceed SLO thresholds. An elevated escape rate doesn’t just show that vulnerabilities exist but it also shows that the process designed to control them is failing, whether because patching cycles are too slow, automation processes are lacking, or compensating controls are not working as intended.\n\nTogether, the metrics create a better picture: arrival rate tells us how much new risk is being introduced; burndown trends show whether we are keeping pace with that pressure or being overwhelmed by it; escape rates expose where vulnerabilities persist despite planned controls.\n\n[1]:An outlier in statistics is a data point that is very far from the central tendency (or far from the rest of the values in a dataset). For example, if most vulnerabilities are patched within 30 days, but one takes 600 days, that 600-day case is an outlier. Outliers can pull averages upward or downward in ways that don’t reflect the “typical” experience. In the patching context, these are the especially slow-to-patch vulnerabilities that sit open far longer than the norm. They may represent rare but important situations, like systems that can’t be easily updated, or patches that require extensive testing. \n\n[2]: Note: The current 6-month dataset includes both all vulnerabilities that remain open at the end of the observation period (independent of how long ago they have been open /first seen) and all vulnerabilities that were closed during the 6-month window. Despite this mixed cohort approach, survival curves from prior observation windows show consistent trends, particularly in the early part of the curve. The shape and slope over the first 30–60 days have proven remarkably stable across snapshots, suggesting that metrics like median time-to-patch and early-stage remediation behavior are not artifacts of the short observation window. While long-term estimates (e.g. 90th percentile) remain incomplete in shorter snapshots, the conclusions drawn from these cohorts still reflect persistent and reliable patching dynamics.\n\n[3]:We kept the CDF on a monthly cadence for operational reporting (throughput and SLO adherence for work completed during the current month), while the Kaplan-Meier uses a 6-month window to properly handle censoring and expose tail risk across the broader cohort.\n","code":"var Component=(()=\u003e{var u=Object.create;var s=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var y=Object.getPrototypeOf,v=Object.prototype.hasOwnProperty;var g=(i,e)=\u003e()=\u003e(e||i((e={exports:{}}).exports,e),e.exports),f=(i,e)=\u003e{for(var n in e)s(i,n,{get:e[n],enumerable:!0})},l=(i,e,n,r)=\u003e{if(e\u0026\u0026typeof e==\"object\"||typeof e==\"function\")for(let a of p(e))!v.call(i,a)\u0026\u0026a!==n\u0026\u0026s(i,a,{get:()=\u003ee[a],enumerable:!(r=m(e,a))||r.enumerable});return i};var w=(i,e,n)=\u003e(n=i!=null?u(y(i)):{},l(e||!i||!i.__esModule?s(n,\"default\",{value:i,enumerable:!0}):n,i)),b=i=\u003el(s({},\"__esModule\",{value:!0}),i);var h=g((k,o)=\u003e{o.exports=_jsx_runtime});var x={};f(x,{default:()=\u003ec,frontmatter:()=\u003e_});var t=w(h()),_={title:\"Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic\",slug:\"time-to-patch-metrics\",date:\"2025-10-22\",description:\"In this article, we describe how we applied survival analysis to vulnerability management (VM) data from Qualys VMDR, using the Elastic Stack.\",author:[{slug:\"laura-voicu\"},{slug:\"clement-fouque\"}],image:\"Security Labs Images 7.jpg\",category:[{slug:\"enablement\"}],tags:[\"qualys\",\"vulnerability\"]};function d(i){let e={a:\"a\",code:\"code\",div:\"div\",em:\"em\",h1:\"h1\",h2:\"h2\",h3:\"h3\",h4:\"h4\",img:\"img\",li:\"li\",p:\"p\",pre:\"pre\",strong:\"strong\",table:\"table\",tbody:\"tbody\",td:\"td\",th:\"th\",thead:\"thead\",tr:\"tr\",ul:\"ul\",...i.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:\"time-to-patch-metrics-a-survival-analysis-approach-using-qualys-and-elastic\",children:\"Time-to-Patch Metrics: A Survival Analysis Approach Using Qualys and Elastic\"}),`\n`,(0,t.jsx)(e.h2,{id:\"introduction\",children:\"Introduction\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Understanding how quickly vulnerabilities are remediated across different environments and teams is critical to maintaining a strong security posture. In this article, we describe how we applied \",(0,t.jsx)(e.strong,{children:\"survival analysis\"}),\" to vulnerability management (VM) data from \",(0,t.jsx)(e.strong,{children:\"Qualys VMDR\"}),\", using the \",(0,t.jsx)(e.strong,{children:\"Elastic Stack\"}),\". This allowed us to not only confirm general assumptions about team velocity (how quickly teams complete work) and remediation capacity (how much fixing they can take on) but also derive measurable insights. Since most of our security data is in the Elastic Stack, this process should be easily reproducible to other security data sources.\"]}),`\n`,(0,t.jsx)(e.h3,{id:\"why-we-did-it\",children:\"Why We Did It\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Our primary motivation was to \",(0,t.jsx)(e.strong,{children:\"move from general assumptions to data-backed insights\"}),\" about:\"]}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"How quickly different teams and environments patch vulnerabilities\"}),`\n`,(0,t.jsx)(e.li,{children:\"Whether patching performance meets internal service level objectives (SLOs)\"}),`\n`,(0,t.jsx)(e.li,{children:\"Where bottlenecks or delays commonly occur\"}),`\n`,(0,t.jsx)(e.li,{children:\"What other factors can affect patching performance\"}),`\n`]}),`\n`,(0,t.jsx)(e.h3,{id:\"why-survival-analysis-a-better-alternative-to-mean-time-to-remediate\",children:\"Why Survival Analysis? A Better Alternative to Mean Time to Remediate\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Mean Time to Remediate (MTTR) is commonly used to track how quickly vulnerabilities are patched, but both the mean and median suffer from significant limitations (we provide an example later in this article). The mean is highly sensitive to \",(0,t.jsx)(e.em,{children:\"outliers\"}),\"[^1] and assumes the remediation times are evenly balanced around the average remediation time, which is rarely the case in practice. The median is less sensitive to extremes but discards information about the shape of the distribution and says nothing about the long tail of slow-to-patch vulnerabilities. Neither accounts for unresolved cases, i.e. vulnerabilities that remain open beyond the observation window, which are often excluded entirely. In practice, the vulnerabilities that remain open the longest are precisely the ones we should be most concerned about.\"]}),`\n`,(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:\"Survival analysis\"}),\" addresses these limitations. Originating in medical and actuarial contexts, it models \",(0,t.jsx)(e.strong,{children:\"time-to-event data\"}),\" while explicitly incorporating \",(0,t.jsx)(e.strong,{children:\"censored observations\"}),\", meaning in our context vulnerabilities that remain open. (For more details on its application to vulnerability management we strongly recommend \",(0,t.jsx)(e.a,{href:\"https://www.themetricsmanifesto.com\",rel:\"nofollow\",children:\"\\u201CThe Metrics Manifesto\\u201D\"}),\"). Instead of collapsing remediation behavior into a single number, survival analysis estimates the probability that a vulnerability remains unpatched over time (e.g. 90% of vulnerabilities are remediated within 30 days). This allows for more meaningful assessments, such as the proportion of vulnerabilities patched within SLO (for example within 30, 90, or 180 days).\"]}),`\n`,(0,t.jsxs)(e.p,{children:[\"Survival analysis provides us with a \",(0,t.jsx)(e.strong,{children:\"survival function\"}),\" that estimates the probability a vulnerability remains unpatched over time.\"]}),`\n`,(0,t.jsx)(e.p,{children:`:::\nThis method offers a better view of remediation performance, allowing us to assess not just how long vulnerabilities persist, but also how remediation behavior differs across systems, teams, or severity levels. It\\u2019s particularly well-suited to security data, which is often incomplete, skewed, and resistant to assumptions of normality.\n:::`}),`\n`,(0,t.jsx)(e.h2,{id:\"context\",children:\"Context\"}),`\n`,(0,t.jsx)(e.p,{children:\"Although we have applied survival analysis across different environments, teams and organizations, in this blog we focus on the results for the Elastic Cloud production environment.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"vulnerability-age-calculation\",children:\"Vulnerability age calculation\"}),`\n`,(0,t.jsx)(e.p,{children:\"There are different methods to calculate vulnerability age.\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"For our internal metrics like \",(0,t.jsx)(e.a,{href:\"https://www.elastic.co/blog/how-infosec-uses-elastic-stack-vulnerability-management\",rel:\"nofollow\",children:\"vulnerability adherence SLO\"}),\", we define vulnerability age as the difference between when a vulnerability was last found and when it was first detected (usually a few days after publication). This approach aims to penalize vulnerabilities that are reintroduced from an outdated base image. In the past, our base images were not updated frequently enough for our satisfaction. If a new instance is created, vulnerabilities can have a significant age (e.g., 100 days) from day one of discovery.\"]}),`\n`,(0,t.jsx)(e.p,{children:\"For this analysis, we find it more relevant to calculate the age based on the number of days between the last found date and the first found date. In this case, age represents the number of days the system was effectively exposed.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"patch-everything-strategy\",children:\"\\u201CPatch everything\\u201D strategy\"}),`\n`,(0,t.jsx)(e.p,{children:\"In our Cloud environment, we maintain a policy to patch everything. This is because we almost exclusively use the same base image across all instances. Since Elastic Cloud operates fully on containers, there are no specific application packages (e.g., Elasticsearch) installed directly on our systems. Our fleet remains homogeneous as a result.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"data-pipeline\",children:\"Data Pipeline\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Ingesting and mapping data into the Elastic Stack can be cumbersome. Luckily, we have \",(0,t.jsx)(e.a,{href:\"https://www.elastic.co/integrations/data-integrations?solution=all-solutions\u0026category=security\",rel:\"nofollow\",children:\"many security integrations\"}),\" that handle those natively, \",(0,t.jsx)(e.a,{href:\"https://www.elastic.co/docs/reference/integrations/qualys_vmdr\",rel:\"nofollow\",children:\"Qualys VMDR\"}),\" being one of them.\"]}),`\n`,(0,t.jsx)(e.p,{children:\"This integration has 3 main interests over custom ingestion methods (e.g. scripts, beats, \\u2026):\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsxs)(e.li,{children:[\"It natively enriches vulnerability data from the Qualys Knowledge Base which add CVE IDs, threat intel information, \\u2026 \",(0,t.jsx)(e.strong,{children:\"without needing to configure enrich pipelines\"}),\".\"]}),`\n`,(0,t.jsxs)(e.li,{children:[\"Qualys data is already mapped to the Elastic Common Schema which is a standardized way of representing data, whether it\\u2019s coming from one source or another: for example, CVEs are always stored in field \",(0,t.jsx)(e.a,{href:\"http://vulnerability.id\",rel:\"nofollow\",children:(0,t.jsx)(e.em,{children:\"vulnerability.id\"})}),\", independent of the source.\"]}),`\n`,(0,t.jsx)(e.li,{children:\"A transform with the latest vulnerability is already set up. This index can be queried to get the latest vulnerabilities status.\"}),`\n`]}),`\n`,(0,t.jsx)(e.h3,{id:\"qualys-agent-integration-configuration\",children:\"Qualys agent integration configuration\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"For survival analysis, we need to ingest both active and patched vulnerabilities. To analyze a specific period, we need to set the number of days in field \",(0,t.jsx)(e.code,{children:\"max_days_since_detection_updated\"}),\". In our environment, we ingest Qualys data daily, so there\\u2019s no need to ingest a long history of fixed data, as we\\u2019ve already done that.\"]}),`\n`,(0,t.jsx)(e.p,{children:\"The Qualys VMDR elastic agent integration has been configured with the following:\"}),`\n`,(0,t.jsx)(e.div,{className:\"table-container\",children:(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{style:{textAlign:\"left\"},children:\"Property\"}),(0,t.jsx)(e.th,{style:{textAlign:\"left\"},children:\"Value\"}),(0,t.jsx)(e.th,{style:{textAlign:\"left\"},children:\"Comment\"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"(Settings section) Username\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"}}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"}})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"(Settings section) Password\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"}}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"Since there are no API keys available in Qualys, we can only authenticate with Basic Authentication.  Make sure SSO is disabled on this account\"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"URL\"}),(0,t.jsxs)(e.td,{style:{textAlign:\"left\"},children:[(0,t.jsx)(e.a,{href:\"https://qualysapi.qg2.apps.qualys.com\",rel:\"nofollow\",children:\"https://qualysapi.qg2.apps.qualys.com\"}),\" (for US2)\"]}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:(0,t.jsx)(e.a,{href:\"https://www.qualys.com/platform-identification/\",rel:\"nofollow\",children:\"https://www.qualys.com/platform-identification/\"})})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"Interval\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"4h\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"Adjust it based on the number of ingested events.\"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"Input parameters\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"show_asset_id=1\u0026 include_vuln_type=confirmed\u0026show_results=1\u0026max_days_since_detection_updated=3\u0026status=New,Active,Re-Opened,Fixed\u0026filter_superseded_qids=1\u0026use_tags=1\u0026tag_set_by=name\u0026tag_include_selector=all\u0026tag_exclude_selector=any\u0026tag_set_include=status:running\u0026tag_set_exclude=status:terminated,status:stopped,status:stale\u0026show_tags=1\u0026show_cloud_tags=1\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"show_asset_id=1: retrieve asset id show_results=1: details about what is the current installed package and which version should be installed max_days_since_detection_updated=3: filter out any vulnerabilities that haven\\u2019t been updated over the last 3 days (e.g. patched older than 3 days) status=New,Active,Re-Opened,Fixed: all vulnerability status are ingested filter_superseded_qids=1: ignore superseded \\u2018vulnerabilities Tags: filter by tags show_tags=1: retrieve Qualys tags show_cloud_tags=1: retrieve Cloud tags\"})]})]})]})}),`\n`,(0,t.jsxs)(e.p,{children:[\"Once data is fully ingested, it can be reviewed either in Kibana Discover (logs-* data view -\u003e \",(0,t.jsx)(e.em,{children:'data_stream.dataset : \"qualys_vmdr.asset_host_detection\"'}),\" ), either in the Kibana Security App (Findings -\u003e Vulnerabilities).\"]}),`\n`,(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:\"/assets/images/time-to-patch-metrics/image6.png\",alt:\"\",width:\"1700\",height:\"835\"})}),`\n`,(0,t.jsx)(e.h3,{id:\"loading-data-into-python-with-the-elasticsearch-client\",children:\"Loading data into Python with the elasticsearch client\"}),`\n`,(0,t.jsx)(e.p,{children:\"Since the survival analysis calculation will be done in Python, we need to extract data from elastic into a python dataframe. There are several ways to achieve this, and in this article we\\u2019ll focus on two of them.\"}),`\n`,(0,t.jsx)(e.h4,{id:\"with-esql\",children:\"With ES|QL\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"The easiest and most convenient way is to leverage ES|QL with the arrow format. It\\u2019ll automatically populate the python dataframe (rows and columns). We recommend reading the blog post \",(0,t.jsx)(e.a,{href:\"https://www.elastic.co/search-labs/blog/esql-pandas-native-dataframes-python\",rel:\"nofollow\",children:\"From ES|QL to native Pandas dataframes in Python\"}),\" to get more details.\"]}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-py\",children:`from elasticsearch import Elasticsearch\nimport pandas as pd\n\nclient = Elasticsearch(\n    \"https://[host].elastic-cloud.com\",\n    api_key=\"...\",\n)\n\nresponse = client.esql.query(\n    query=\"\"\"\n   FROM logs-qualys_vmdr.asset_host_detection-default\n    | WHERE elastic.owner.team == \"platform-security\" AND elastic.environment == \"production\"\n    | WHERE qualys_vmdr.asset_host_detection.vulnerability.is_ignored == FALSE\n    | EVAL vulnerability_age = DATE_DIFF(\"day\", qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime, qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime)\n    | STATS \n        mean=AVG(vulnerability_age), \n        median=MEDIAN(vulnerability_age)\n    \"\"\",\n    format=\"arrow\",\n)\ndf = response.to_pandas(types_mapper=pd.ArrowDtype)\nprint(df)\n`})}),`\n`,(0,t.jsxs)(e.p,{children:[\"Today, we have a limitation with ESQL: we can\\u2019t paginate through results. Therefore we are limited to 10K output documents (100K if server configuration is modified). Progress can be followed through this \",(0,t.jsx)(e.a,{href:\"https://github.com/elastic/elasticsearch/issues/100000\",rel:\"nofollow\",children:\"enhancement request\"}),\".\"]}),`\n`,(0,t.jsx)(e.h4,{id:\"with-dsl\",children:\"With DSL\"}),`\n`,(0,t.jsx)(e.p,{children:\"In the elasticsearch python client, there is a native feature to extract all the data from a query with transparent pagination. The challenging part is to create the DSL query. We recommend creating the query in Discover and then click on Inspect, and then Request tab to get the DSL query.\"}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-py\",children:`query = {\n    \"track_total_hits\": True,\n    \"query\": {\n        \"bool\": {\n            \"filter\": [\n                {\n                    \"match\": {\n                        \"elastic.owner.team\": \"awesome-sre-team\"\n                    }\n                },\n                {\n                    \"match\": {\n                        \"elastic.environment\": \"production\"\n                    }\n                },\n                {\n                    \"match\": {\n\"qualys_vmdr.asset_host_detection.vulnerability.is_ignored\": False\n                    }\n                }\n            ]\n        }\n    },\n    \"fields\": [\n        \"@timestamp\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.unique_vuln_id\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime\",\n        \"elastic.vulnerability.age\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.status\",\n        \"vulnerability.severity\",\n        \"qualys_vmdr.asset_host_detection.vulnerability.is_ignored\"\n    ],\n    \"_source\": False\n}\n\nresults = list(scan(\n        client=es,\n        query=query,\n        scroll='30m',\n        index=source_index,\n        size=10000,\n        raise_on_error=True,\n        preserve_order=False,\n        clear_scroll=True\n    ))\n`})}),`\n`,(0,t.jsx)(e.h2,{id:\"survival-analysis\",children:\"Survival Analysis\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"You can refer to the \",(0,t.jsx)(e.a,{href:\"https://github.com/lauravoicu/elastic-vm-survivalanalysis/tree/main\",rel:\"nofollow\",children:\"code\"}),\" to understand or reproduce it on your dataset.\"]}),`\n`,(0,t.jsx)(e.h2,{id:\"what-we-learned\",children:\"What We Learned\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Leaning in on the research from the \",(0,t.jsx)(e.a,{href:\"https://www.cyentia.com/why-your-mttr-is-probably-bogus/\",rel:\"nofollow\",children:\"Cyentia Institute\"}),\" we looked at a few different ways to measure how long it takes to remediate vulnerabilities using means, medians, and survival curves. Each method gives a different lens through which we can understand time-to-patch data, and the comparison is important because depending on which method we use, we would draw very different conclusions about how well vulnerabilities are being addressed.\"]}),`\n`,(0,t.jsx)(e.p,{children:\"The first method focuses only on vulnerabilities that have already been closed. It calculates the median and mean time it took to patch them. This is intuitive and simple, but it leaves out a potentially large and important portion of the data (the vulnerabilities that are still open). As a result, it tends to underestimate the true time it takes to remediate, especially if some vulnerabilities stay open much longer than others.\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"The second method tries to include both closed and open vulnerabilities by using the time they\\u2019ve been open \",(0,t.jsx)(e.em,{children:\"so far\"}),\". There are many options to approximate a time-to-patch for the open vulnerabilities, but for simplicity here we assumed they were (will be?) patched at the time of reporting, which we know isn\\u2019t true. But it does offer a way to factor in their existence.\"]}),`\n`,(0,t.jsx)(e.p,{children:\"The third method uses survival analysis. Specifically, we used the Kaplan-Meier estimator to model the likelihood that a vulnerability is still open at any given time. This method handles the open vulnerabilities properly: instead of pretending they\\u2019re patched, it treats them as \\u201Ccensored\\u201D data. The survival curve it produces drops over time, showing the proportion of vulnerabilities still open as days or weeks pass.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"how-long-do-vulnerabilities-last\",children:\"How Long Do Vulnerabilities Last?\"}),`\n`,(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:\"/assets/images/time-to-patch-metrics/image4.png\",alt:\"\",width:\"1999\",height:\"1000\"})}),`\n`,(0,t.jsx)(e.p,{children:\"In the current 6-month snapshot[^2], the closed-only time-to-patch has a median ~33 days and a mean ~35 days. On the surface that looks reasonable, but the Kaplan-Meier curve shows what those numbers hide: at 33 days, ~54% are still open; at 35 days, ~46% are still open. So even around the \\u201Ctypical\\u201D one-month mark, about half of issues remain unresolved.\"}),`\n`,(0,t.jsx)(e.p,{children:\"We also computed observed-so-far statistics (treating open vulnerabilities as if they were patched at the end of the measurement window). In this window they happen to be almost the same (median ~33 days, mean ~35 days) because the ages of today\\u2019s open items cluster near one month. That coincidence can make averages look reassuring, but it\\u2019s incidental and unstable: if we shift the snapshot to just before the monthly patch push and these same statistics drop sharply (we\\u2019ve seen an observed median of ~19 days and observed a mean of ~15 days) without any change in the underlying process.\"}),`\n`,(0,t.jsx)(e.p,{children:\"The survival curve avoids that trap, because it answers the question of \\u201C% still open after 30/60/90 days\\u201D, and offers visibility into the long tail that stays open well past a month.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"patch-everything-everywhere-the-same-way\",children:\"Patch Everything Everywhere The Same Way?\"}),`\n`,(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:\"/assets/images/time-to-patch-metrics/image5.png\",alt:\"\",width:\"1999\",height:\"1000\"})}),`\n`,(0,t.jsx)(e.p,{children:\"Stratified survival analysis takes the idea of survival curves one step further. Instead of looking at all vulnerabilities together in one big pool, it separates them into groups (or \\u201Cstrata\\u201D) based on some meaningful characteristic. In our analysis, we have stratified vulnerabilities by severity, asset criticality, environment, cloud provider, team/division/organization. Each group gets its own survival curve, and here in the example graph we compare how quickly different vulnerability severities are remediated over time.\"}),`\n`,(0,t.jsx)(e.p,{children:\"The benefit of this approach is that it exposes differences that would otherwise be hidden in the aggregate. If we only looked at the overall survival curve, we can only make conclusions about the remediation performance across the board. But stratification reveals if different teams, environments or severity issues are addressed faster than the rest, and in our case that the patch everything strategy is indeed consistent. This level of detail is important for making targeted improvements, helping us understand not just how long remediation takes in general, but if and where real bottlenecks exist.\"}),`\n`,(0,t.jsx)(e.h3,{id:\"how-fast-do-teams-act\",children:\"How Fast Do Teams Act?\"}),`\n`,(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:\"/assets/images/time-to-patch-metrics/image2.png\",alt:\"\",width:\"1999\",height:\"1200\"})}),`\n`,(0,t.jsx)(e.p,{children:\"While the survival curve emphasizes how long vulnerabilities remain open, we can flip the perspective by using the cumulative distribution function (CDF) instead. The CDF focuses on how quickly vulnerabilities are patched, showing the proportion of vulnerabilities that have been remediated by a given point in time.\"}),`\n`,(0,t.jsx)(e.p,{children:\"Our choice of plotting the CDF provides a clear picture of remediation speed, however it\\u2019s important to note that this version includes only vulnerabilities that were patched within the observed time window. Unlike the survival curve which we compute over a rolling 6-month cohort to capture full lifecycles, the CDF is computed month-over-month on items closed in that month[^3].\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"As such, it tells us how quickly teams remediate vulnerabilities \",(0,t.jsx)(e.strong,{children:\"once they do so\"}),\", and it doesn\\u2019t reflect how long unresolved vulnerabilities remain open. For example, we see that 83.2% of the vulnerabilities closed in the current month were resolved within 30 days of the first detection. This highlights patching velocity for recent, successful patches but does not account for longer-standing vulnerabilities that remain open and are likely to have longer time-to-patch durations. Therefore, we use the CDF for understanding short-term response behavior, whereas the full lifecycle dynamics are given by a combination of CDF alongside survival analysis: the CDF describes \",(0,t.jsx)(e.em,{children:\"how fast teams act\"}),\" once they patch, whereas the survival curve shows \",(0,t.jsx)(e.em,{children:\"how long vulnerabilities truly last\"}),\".\"]}),`\n`,(0,t.jsx)(e.h2,{id:\"difference-between-survival-analysis-and-meanmedian\",children:\"Difference Between Survival Analysis and Mean/Median\"}),`\n`,(0,t.jsx)(e.p,{children:\"Wait, we said that survival analysis is better to analyze time to patch to avoid the impact of outliers. But in this example, mean/median and survival analysis provide similar results. What is the added value? The reason is simple: we don\\u2019t have outliers in our production environments since our patching process is fully automated and effective.\"}),`\n`,(0,t.jsx)(e.p,{children:\"To demonstrate the impact on heterogeneous data, we\\u2019ll use an outdated example from a non-production environment that lacks automated patching.\"}),`\n`,(0,t.jsx)(e.p,{children:\"ESQL query:\"}),`\n`,(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:\"language-sql\",children:`FROM qualys_vmdr.vulnerability_6months\n  | WHERE elastic.environment == \"my-outdated-non-production-environment\"\n  | WHERE qualys_vmdr.asset_host_detection.vulnerability.is_ignored == FALSE\n  | EVAL vulnerability_age = DATE_DIFF(\"day\", qualys_vmdr.asset_host_detection.vulnerability.first_found_datetime, qualys_vmdr.asset_host_detection.vulnerability.last_found_datetime)\n  | STATS\n      count=COUNT(*),\n      count_closed_only=COUNT(*) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == \"Fixed\",\n      mean_observed_so_far=MEDIAN(vulnerability_age),\n      mean_closed_only=MEDIAN(vulnerability_age) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == \"Fixed\",\n      median_observed_so_far=MEDIAN(vulnerability_age),\n      median_closed_only=MEDIAN(vulnerability_age) WHERE qualys_vmdr.asset_host_detection.vulnerability.status == \"Fixed\"\n`})}),`\n`,(0,t.jsx)(e.div,{className:\"table-container\",children:(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{style:{textAlign:\"left\"}}),(0,t.jsx)(e.th,{style:{textAlign:\"left\"},children:\"Observed so far\"}),(0,t.jsx)(e.th,{style:{textAlign:\"left\"},children:\"Closed only\"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"Count\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"833\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"322\"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"Mean\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"178.7 (days)\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"163.8 (days)\"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"Median\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"61 (days)\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"5 (days)\"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"Median survival\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"527 (days)\"}),(0,t.jsx)(e.td,{style:{textAlign:\"left\"},children:\"N/A\"})]})]})]})}),`\n`,(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:\"/assets/images/time-to-patch-metrics/image1.png\",alt:\"\",width:\"1999\",height:\"1000\"})}),`\n`,(0,t.jsx)(e.p,{children:\"In this example, using mean and median yield very different results. Choosing a single representative metric can be challenging and potentially misleading. The survival analysis graph accurately represents our effectiveness in addressing vulnerabilities within this environment.\"}),`\n`,(0,t.jsx)(e.h2,{id:\"final-thoughts\",children:\"Final Thoughts\"}),`\n`,(0,t.jsx)(e.p,{children:\"The benefits of using survival analysis come not only from more accurate measurement but also from the insights into the dynamics of patching behaviour, showing where bottlenecks occur, factors that affect patching velocity and whether it aligns with our SLO. From a technical integration perspective, the use of survival analysis as part of our operational workflows and reporting can be achieved with minimal additional changes to our current Elastic Stack setup: survival analysis can run on the same cadence as our patching cycle with the results being pushed back into Kibana for visualization. The definitive advantage is to pair our existing operational metrics with survival analysis for both long-term trends and short-term performance tracking.\"}),`\n`,(0,t.jsxs)(e.p,{children:[\"Looking forward, we\\u2019re experimenting with additional new metrics like \",(0,t.jsx)(e.strong,{children:\"Arrival Rate\"}),\", \",(0,t.jsx)(e.strong,{children:\"Burndown Rate\"}),\", and \",(0,t.jsx)(e.strong,{children:\"Escape Rate\"}),\" that give us a way to move toward a more dynamic understanding of how vulnerabilities are really handled.\"]}),`\n`,(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:\"Arrival Rate\"}),\" is the measure of how quickly new vulnerabilities are entering the environment. Knowing that fifty new CVEs show up each month, for example, tells us what to expect in the workload before we even start measuring patches. So the arrival rate is a metric that does not necessarily inform about the backlog, but more about the pressure applied to the system.\"]}),`\n`,(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:\"Burndown Rate\"}),\" (trend) shows the other half of the equation: how quickly vulnerabilities are being remediated relative to how fast they arrive.\"]}),`\n`,(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:\"Escape Rate\"}),\" adds yet another dimension by focusing on vulnerabilities that slip past the points where they should have been contained. In our context, an escape is about CVEs that miss patching windows or exceed SLO thresholds. An elevated escape rate doesn\\u2019t just show that vulnerabilities exist but it also shows that the process designed to control them is failing, whether because patching cycles are too slow, automation processes are lacking, or compensating controls are not working as intended.\"]}),`\n`,(0,t.jsx)(e.p,{children:\"Together, the metrics create a better picture: arrival rate tells us how much new risk is being introduced; burndown trends show whether we are keeping pace with that pressure or being overwhelmed by it; escape rates expose where vulnerabilities persist despite planned controls.\"}),`\n`,(0,t.jsx)(e.p,{children:\"[1]:An outlier in statistics is a data point that is very far from the central tendency (or far from the rest of the values in a dataset). For example, if most vulnerabilities are patched within 30 days, but one takes 600 days, that 600-day case is an outlier. Outliers can pull averages upward or downward in ways that don\\u2019t reflect the \\u201Ctypical\\u201D experience. In the patching context, these are the especially slow-to-patch vulnerabilities that sit open far longer than the norm. They may represent rare but important situations, like systems that can\\u2019t be easily updated, or patches that require extensive testing.\"}),`\n`,(0,t.jsx)(e.p,{children:\"[2]: Note: The current 6-month dataset includes both all vulnerabilities that remain open at the end of the observation period (independent of how long ago they have been open /first seen) and all vulnerabilities that were closed during the 6-month window. Despite this mixed cohort approach, survival curves from prior observation windows show consistent trends, particularly in the early part of the curve. The shape and slope over the first 30\\u201360 days have proven remarkably stable across snapshots, suggesting that metrics like median time-to-patch and early-stage remediation behavior are not artifacts of the short observation window. While long-term estimates (e.g. 90th percentile) remain incomplete in shorter snapshots, the conclusions drawn from these cohorts still reflect persistent and reliable patching dynamics.\"}),`\n`,(0,t.jsx)(e.p,{children:\"[3]:We kept the CDF on a monthly cadence for operational reporting (throughput and SLO adherence for work completed during the current month), while the Kaplan-Meier uses a 6-month window to properly handle censoring and expose tail risk across the broader cohort.\"})]})}function c(i={}){let{wrapper:e}=i.components||{};return e?(0,t.jsx)(e,{...i,children:(0,t.jsx)(d,{...i})}):d(i)}return b(x);})();\n;return Component;"},"_id":"articles/time-to-patch-metrics.mdx","_raw":{"sourceFilePath":"articles/time-to-patch-metrics.mdx","sourceFileName":"time-to-patch-metrics.mdx","sourceFileDir":"articles","contentType":"mdx","flattenedPath":"articles/time-to-patch-metrics"},"type":"Article","imageUrl":"/assets/images/time-to-patch-metrics/Security Labs Images 7.jpg","readingTime":"19 min read","series":"","url":"/time-to-patch-metrics","headings":[{"level":2,"title":"Introduction","href":"#introduction"},{"level":3,"title":"Why We Did It","href":"#why-we-did-it"},{"level":3,"title":"Why Survival Analysis? A Better Alternative to Mean Time to Remediate","href":"#why-survival-analysis-a-better-alternative-to-mean-time-to-remediate"},{"level":2,"title":"Context","href":"#context"},{"level":3,"title":"Vulnerability age calculation","href":"#vulnerability-age-calculation"},{"level":3,"title":"“Patch everything” strategy","href":"#patch-everything-strategy"},{"level":2,"title":"Data Pipeline","href":"#data-pipeline"},{"level":3,"title":"Qualys agent integration configuration","href":"#qualys-agent-integration-configuration"},{"level":3,"title":"Loading data into Python with the elasticsearch client","href":"#loading-data-into-python-with-the-elasticsearch-client"},{"level":4,"title":"With ES|QL","href":"#with-esql"},{"level":4,"title":"With DSL","href":"#with-dsl"},{"level":2,"title":"Survival Analysis","href":"#survival-analysis"},{"level":2,"title":"What We Learned","href":"#what-we-learned"},{"level":3,"title":"How Long Do Vulnerabilities Last?","href":"#how-long-do-vulnerabilities-last"},{"level":3,"title":"Patch Everything Everywhere The Same Way?","href":"#patch-everything-everywhere-the-same-way"},{"level":3,"title":"How Fast Do Teams Act?","href":"#how-fast-do-teams-act"},{"level":2,"title":"Difference Between Survival Analysis and Mean/Median","href":"#difference-between-survival-analysis-and-meanmedian"},{"level":2,"title":"Final Thoughts","href":"#final-thoughts"}],"author":[{"title":"Laura Voicu","slug":"laura-voicu","description":"Principal Information Security Analyst I","body":{"raw":"","code":"var Component=(()=\u003e{var x=Object.create;var a=Object.defineProperty;var f=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var _=Object.getPrototypeOf,d=Object.prototype.hasOwnProperty;var g=(t,n)=\u003e()=\u003e(n||t((n={exports:{}}).exports,n),n.exports),j=(t,n)=\u003e{for(var r in n)a(t,r,{get:n[r],enumerable:!0})},u=(t,n,r,i)=\u003e{if(n\u0026\u0026typeof n==\"object\"||typeof n==\"function\")for(let o of p(n))!d.call(t,o)\u0026\u0026o!==r\u0026\u0026a(t,o,{get:()=\u003en[o],enumerable:!(i=f(n,o))||i.enumerable});return t};var y=(t,n,r)=\u003e(r=t!=null?x(_(t)):{},u(n||!t||!t.__esModule?a(r,\"default\",{value:t,enumerable:!0}):r,t)),M=t=\u003eu(a({},\"__esModule\",{value:!0}),t);var s=g((I,c)=\u003e{c.exports=_jsx_runtime});var D={};j(D,{default:()=\u003el,frontmatter:()=\u003eC});var e=y(s()),C={title:\"Laura Voicu\",description:\"Principal Information Security Analyst I\",slug:\"laura-voicu\"};function m(t){return(0,e.jsx)(e.Fragment,{})}function l(t={}){let{wrapper:n}=t.components||{};return n?(0,e.jsx)(n,{...t,children:(0,e.jsx)(m,{...t})}):m(t)}return M(D);})();\n;return Component;"},"_id":"authors/laura-voicu.mdx","_raw":{"sourceFilePath":"authors/laura-voicu.mdx","sourceFileName":"laura-voicu.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/laura-voicu"},"type":"Author","imageUrl":"","url":"/authors/laura-voicu"},{"title":"Clement Fouque","slug":"clement-fouque","description":"Principal Information Security Analyst I","body":{"raw":"","code":"var Component=(()=\u003e{var f=Object.create;var u=Object.defineProperty;var x=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var _=Object.getPrototypeOf,d=Object.prototype.hasOwnProperty;var g=(t,e)=\u003e()=\u003e(e||t((e={exports:{}}).exports,e),e.exports),j=(t,e)=\u003e{for(var n in e)u(t,n,{get:e[n],enumerable:!0})},i=(t,e,n,a)=\u003e{if(e\u0026\u0026typeof e==\"object\"||typeof e==\"function\")for(let o of p(e))!d.call(t,o)\u0026\u0026o!==n\u0026\u0026u(t,o,{get:()=\u003ee[o],enumerable:!(a=x(e,o))||a.enumerable});return t};var y=(t,e,n)=\u003e(n=t!=null?f(_(t)):{},i(e||!t||!t.__esModule?u(n,\"default\",{value:t,enumerable:!0}):n,t)),C=t=\u003ei(u({},\"__esModule\",{value:!0}),t);var m=g((D,c)=\u003e{c.exports=_jsx_runtime});var M={};j(M,{default:()=\u003el,frontmatter:()=\u003eF});var r=y(m()),F={title:\"Clement Fouque\",description:\"Principal Information Security Analyst I\",slug:\"clement-fouque\"};function s(t){return(0,r.jsx)(r.Fragment,{})}function l(t={}){let{wrapper:e}=t.components||{};return e?(0,r.jsx)(e,{...t,children:(0,r.jsx)(s,{...t})}):s(t)}return C(M);})();\n;return Component;"},"_id":"authors/clement-fouque.mdx","_raw":{"sourceFilePath":"authors/clement-fouque.mdx","sourceFileName":"clement-fouque.mdx","sourceFileDir":"authors","contentType":"mdx","flattenedPath":"authors/clement-fouque"},"type":"Author","imageUrl":"","url":"/authors/clement-fouque"}],"category":[{"title":"Enablement","slug":"enablement","body":{"raw":"","code":"var Component=(()=\u003e{var l=Object.create;var a=Object.defineProperty;var f=Object.getOwnPropertyDescriptor;var _=Object.getOwnPropertyNames;var d=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var j=(t,e)=\u003e()=\u003e(e||t((e={exports:{}}).exports,e),e.exports),p=(t,e)=\u003e{for(var n in e)a(t,n,{get:e[n],enumerable:!0})},s=(t,e,n,m)=\u003e{if(e\u0026\u0026typeof e==\"object\"||typeof e==\"function\")for(let o of _(e))!g.call(t,o)\u0026\u0026o!==n\u0026\u0026a(t,o,{get:()=\u003ee[o],enumerable:!(m=f(e,o))||m.enumerable});return t};var M=(t,e,n)=\u003e(n=t!=null?l(d(t)):{},s(e||!t||!t.__esModule?a(n,\"default\",{value:t,enumerable:!0}):n,t)),b=t=\u003es(a({},\"__esModule\",{value:!0}),t);var c=j((X,u)=\u003e{u.exports=_jsx_runtime});var D={};p(D,{default:()=\u003ei,frontmatter:()=\u003eC});var r=M(c()),C={title:\"Enablement\",slug:\"enablement\"};function x(t){return(0,r.jsx)(r.Fragment,{})}function i(t={}){let{wrapper:e}=t.components||{};return e?(0,r.jsx)(e,{...t,children:(0,r.jsx)(x,{...t})}):x(t)}return b(D);})();\n;return Component;"},"_id":"categories/enablement.mdx","_raw":{"sourceFilePath":"categories/enablement.mdx","sourceFileName":"enablement.mdx","sourceFileDir":"categories","contentType":"mdx","flattenedPath":"categories/enablement"},"type":"Category","url":"/categories/enablement"}]},"seriesArticles":null},"__N_SSG":true},"page":"/[slug]","query":{"slug":"time-to-patch-metrics"},"buildId":"t22lc240R6yUreqPiT9Cj","assetPrefix":"/security-labs","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>